{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "colors = {\"human\": \"#000000\", \"self_class\": \"#19c202\", \"random\": \"#9c2200\", \"a2c_training\": \"#89CFF0\",\n",
    "          \"trpo_training\": \"#0000FF\",\n",
    "          \"acer_training\": \"#7393B3\", \"ppo2_training\": \"#0096FF\", \"dqn_training\": \"#5D3FD3\"}\n",
    "\n",
    "game_titles = {\n",
    "    \"shuffleKeys_game\": \"Switching Mappings Keys Game\",\n",
    "    \"shuffleKeys_game_final\": \"Switching Mappings Keys Game\",\n",
    "    \"contingency_game\": \"Contingency Game\",\n",
    "    \"contingency_game_final\": \"Contingency Game\",\n",
    "    \"contingency_game_0\": \"Contingency Game (Single Seed)\",\n",
    "    \"contingency_game_lrtest\": \"Contingency Game (Single Seed)\",\n",
    "    \"contingency_game_r0\": \"Contingency Game (Agent Placement is Constant Among Each Level)\",\n",
    "    \"contingency_game_diff_color\": \"Contingency Game (Real Agent is Blue)\",\n",
    "    \"contingency_game_shuffled\": \"Switching Mappings Game (Switched Once in Every 200 Levels)\",\n",
    "    \"contingency_game_shuffled_1\": \"Switching Mappings Game (Switched Every Level)\",\n",
    "    \"contingency_game_shuffled_100\": \"Switching Mappings Game (Switched Once in Every 100 Levels)\",\n",
    "    \"contingency_game_shuffled_200\": \"Switching Mappings Game (Switched Once in Every 200 Levels)\",\n",
    "    \"contingency_game_shuffled_final\": \"Switching Mappings Game (Switched Once in Every 200 Levels)\",\n",
    "    \"contingency_game_shuffled_1_final\": \"Switching Mappings Game (Switched Every Level)\",\n",
    "    \"contingency_game_shuffled_100_final\": \"Switching Mappings Game (Switched Once in Every 100 Levels)\",\n",
    "    \"contingency_game_shuffled_200_final\": \"Switching Mappings Game (Switched Once in Every 200 Levels)\",\n",
    "    \"logic_game\": \"Logic Game\",\n",
    "    \"logic_game_final\": \"Logic Game\",\n",
    "    \"logic_game_0\": \"Logic Game\",\n",
    "    \"logic_game_lrtest\": \"Logic Game\",\n",
    "    \"logic_extended_game\": \"Logic Game (Modified After 2000 Levels)\",\n",
    "    \"change_agent_game\": \"Switching Embodiments Game\",\n",
    "    \"change_agent_game_final\": \"Switching Embodiments Game\",\n",
    "    \"change_agent_game_lrtest\": \"Switching Embodiments Game (Single Seed)\"\n",
    "}\n",
    "\n",
    "label_dict = {'human': 'Human', 'self_class': 'Self Class', 'dqn_training': 'DQN',\n",
    "              'random': 'Random', 'a2c_training': \"A2C\", 'trpo_training': 'TRPO', 'ppo2_training': 'PPO2',\n",
    "              'acer_training': 'ACER'}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# batch_size = Average per N levels\n",
    "# single_seed=True plots only a single seed (For testing)\n",
    "def get_performance(game_types, agent_types, batch_size=10, single_seed=False):\n",
    "    ''' Plot performance for games and agents'''\n",
    "    param_dict = {}\n",
    "\n",
    "    ## ----- Read in data\n",
    "    for i, game_type in enumerate(game_types):\n",
    "        param_dict[game_type] = {}\n",
    "        for agent_type in agent_types:\n",
    "            files = glob.glob(\"../data/\" + game_type + \"/\" + agent_type + \"/*/*.json\")\n",
    "            if len(files) == 0:\n",
    "                files = glob.glob(\"../data/\" + game_type + \"/\" + agent_type + \"/*.json\")\n",
    "\n",
    "            seed = 0\n",
    "            curr_file_count = 0\n",
    "            file_amt = len(files)\n",
    "            param_dict[game_type][agent_type] = {}\n",
    "            seed_current = []\n",
    "            all_seeds = []\n",
    "            seed_total = 10 if not single_seed else 1\n",
    "\n",
    "            def get_seed_num_and_iter(x):\n",
    "                return int(x.split(\"/\")[4][4]) * 1000000000 + int(x.split(\"/\")[-1][6:-5])\n",
    "\n",
    "            sorted_files = sorted(files, key=os.path.getmtime if agent_type == 'human' else get_seed_num_and_iter)\n",
    "            for i, file in enumerate(sorted_files):\n",
    "                with open(file, 'r') as fp:\n",
    "                    print(\"Getting \", file, \"...\")\n",
    "                    data = json.load(fp)\n",
    "                    param_dict[game_type][agent_type] = data['data']['steps']\n",
    "                    curr_file_count += 1\n",
    "\n",
    "                    seed_current.append(data['data']['steps'])\n",
    "\n",
    "                    if agent_type == 'human' and (file_amt == 1 or single_seed):\n",
    "                        param_dict[game_type][agent_type] = [data['data']['steps']]\n",
    "                        break\n",
    "                    else:\n",
    "                        if agent_type == 'human' and curr_file_count == file_amt:\n",
    "                            param_dict[game_type][agent_type] = seed_current\n",
    "                            break\n",
    "\n",
    "                    if agent_type != 'human' and curr_file_count == 20:\n",
    "                        all_seeds.append(seed_current)\n",
    "                        seed_current = []\n",
    "                        curr_file_count = 0\n",
    "                        seed += 1\n",
    "\n",
    "                    if seed == seed_total:\n",
    "                        param_dict[game_type][agent_type] = all_seeds\n",
    "                        all_seeds = []\n",
    "\n",
    "                        if single_seed:\n",
    "                            break\n",
    "\n",
    "    ## ---- Get descriptive statistics\n",
    "    stats_dict = {}\n",
    "    for game_type in game_types:\n",
    "        stats_dict[game_type] = {}\n",
    "        for agent_type in agent_types:\n",
    "            raw_data = pd.DataFrame(param_dict[game_type][agent_type])\n",
    "\n",
    "            seed_average = []\n",
    "            seed_sem = []\n",
    "            for column in raw_data:\n",
    "                seed_average.append(np.mean(list(raw_data[column]), axis=0))\n",
    "                seed_sem.append((pd.DataFrame(list(raw_data[column]))).sem(axis=0))\n",
    "\n",
    "            curr_avg_data = pd.DataFrame(seed_average).T\n",
    "            curr_sem_data = pd.DataFrame(seed_sem).T\n",
    "            stats_dict[game_type][agent_type] = raw_data\n",
    "\n",
    "            if agent_type != 'human':  # Average per N levels for AI\n",
    "                stats_dict[game_type][agent_type + \"_m\"] = np.array(\n",
    "                    [curr_avg_data[column].groupby(curr_avg_data.index // batch_size).mean() for column in\n",
    "                     curr_avg_data]).reshape(\n",
    "                    int(curr_avg_data.shape[1] * 100 * 1 / batch_size))\n",
    "                stats_dict[game_type][agent_type + \"_se\"] = np.array(\n",
    "                    [curr_sem_data[column].groupby(curr_sem_data.index // batch_size).mean() for column in\n",
    "                     curr_sem_data]).reshape(\n",
    "                    int(curr_sem_data.shape[1] * 100 * 1 / batch_size))\n",
    "            else:  # Average per N levels for Human data\n",
    "                temp = np.asarray(curr_avg_data).T\n",
    "                avg_ma = [temp[i:i + batch_size].mean() for i in\n",
    "                          range(0, curr_avg_data.shape[1] - batch_size + 1, batch_size)]\n",
    "\n",
    "                temp = np.asarray(curr_sem_data).T\n",
    "                avg_se = [temp[i:i + batch_size].mean() for i in\n",
    "                          range(0, curr_sem_data.shape[1] - batch_size + 1, batch_size)]\n",
    "\n",
    "                stats_dict[game_type][agent_type + \"_m\"] = np.array(avg_ma).reshape(\n",
    "                    int(curr_avg_data.shape[1] / batch_size))\n",
    "                stats_dict[game_type][agent_type + \"_se\"] = np.array(avg_se).reshape(\n",
    "                    int(curr_sem_data.shape[1] / batch_size))\n",
    "\n",
    "    ## ---- Plot data\n",
    "    return stats_dict, game_types, agent_types, batch_size\n",
    "\n",
    "\n",
    "# combined=True: Plots the stress tests\n",
    "# only_first_100=True: Plots only the first hundred\n",
    "# last_100=True: Plots only the last hundred\n",
    "def plotter(stats, game_types, agent_types, batch_size, combined=False, only_first_100=False, last_100=False):\n",
    "    for i, game_type in enumerate(game_types):\n",
    "        st = stats[game_type]\n",
    "\n",
    "        jdata = {}\n",
    "        for a in agent_types:\n",
    "            if a == 'human':\n",
    "                jdata[a] = st['human'].T.values.tolist()\n",
    "                jdata[a + '_avg'] = np.mean(st[a + '_m'])\n",
    "            else:\n",
    "                jdata[a + '_first_100'] = np.asarray([t[:100] for t in list(st[a].iloc[:,0:].values.T)[0]]).T.tolist()\n",
    "                jdata[a + '_first_100_avg'] = np.mean(st[a + '_m'][:100])\n",
    "                jdata[a + '_last_100'] = np.asarray([t[:100] for t in list(st[a].iloc[:,-1:].values.T)[0]]).T.tolist()\n",
    "                jdata[a + '_last_100_avg'] = np.mean(st[a + '_m'][-100:])\n",
    "\n",
    "        print(\"opening: \", '../stats/data_{}.json'.format(game_type))\n",
    "        #try:\n",
    "        #    with open('../stats/data_{}.json'.format(game_type), 'w+') as fp:  # Save data files\n",
    "        #        print(\"saving: \", jdata)\n",
    "        #        json.dump(jdata, fp, indent=4)\n",
    "        #except Exception as e:\n",
    "        #    print(e)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "        # Hide the right and top spines\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "\n",
    "        axes = plt.gca()\n",
    "\n",
    "        ##### Cosmetic #####\n",
    "        if game_type == 'contingency_game_shuffled':\n",
    "            axes.set_ylim([0, 6000])\n",
    "        elif game_type == 'change_agent_game':\n",
    "            axes.set_ylim([0, 750])\n",
    "        elif game_type in ['contingency_game', 'contingency_game_diff_color', 'contingency_game_0',\n",
    "                           ]:\n",
    "            if not last_100:\n",
    "                axes.set_ylim([0, 800])\n",
    "        elif game_type == \"contingency_game_shuffled_200\":\n",
    "            axes.set_ylim([0, 4000])\n",
    "        elif game_type in [\"contingency_game_shuffled_100\", \"contingency_game_shuffled_1\"]:\n",
    "            axes.set_ylim([0, 6000])\n",
    "            if game_type == \"contingency_game_shuffled_1\" and last_100:\n",
    "                axes.set_ylim([0, 2000])\n",
    "        elif game_type == 'logic_game':\n",
    "            axes.set_ylim([0, 100])\n",
    "\n",
    "        if combined and game_type in ['contingency_game']:\n",
    "            axes.set_ylim([0, 600])\n",
    "\n",
    "        if len(agent_types) == 2:\n",
    "            axes.set_xlim([0, 120])\n",
    "            axes.set_ylim([0, 13]) if game_type == 'logic_game' else axes.set_ylim([0, 50])\n",
    "            if game_type == \"change_agent_game\":\n",
    "                axes.set_ylim([0, 100])\n",
    "\n",
    "        if only_first_100:\n",
    "            axes.set_xlim([0, 100])\n",
    "\n",
    "        if last_100 and game_type == \"contingency_game\":\n",
    "            axes.set_ylim([0, 50])\n",
    "        elif last_100 and game_type == \"change_agent_game\":\n",
    "            axes.set_ylim([0, 160])\n",
    "        elif only_first_100 and game_type == \"change_agent_game\":\n",
    "            axes.set_ylim([0, 160])\n",
    "        elif last_100 and game_type == \"contingency_game_shuffled_100\":\n",
    "            axes.set_ylim([0, 2500])\n",
    "        elif (only_first_100 or last_100) and game_type == \"logic_game\":\n",
    "            axes.set_ylim([0, 20])\n",
    "\n",
    "\n",
    "        y_str = \"No. Steps To Complete Level\" + '\\nAveraged Every {} Levels'.format(batch_size)\n",
    "        if batch_size == 1:\n",
    "            y_str = \"No. Steps To Complete Level\"\n",
    "\n",
    "        if not only_first_100 and not last_100:\n",
    "            ax.set_ylabel(ylabel=y_str, labelpad=21, fontsize=25)\n",
    "            ax.set_xlabel(xlabel=\"Levels Played\", labelpad=21, fontsize=25)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=27)\n",
    "        else:\n",
    "            ax.tick_params(axis='both', which='major', labelsize=40)\n",
    "\n",
    "        for j, agent_type in enumerate(agent_types):  # Plot each line\n",
    "            if agent_type != 'human':  # AI\n",
    "\n",
    "                xs = [int(i * batch_size) for i in range(0, len(st[agent_type + \"_m\"]))]\n",
    "                temp_xs = []\n",
    "                if last_100:\n",
    "                    for a in xs:\n",
    "                        if a < 100:\n",
    "                            temp_xs.append(a)\n",
    "                    xs = temp_xs\n",
    "                    r_l = ax.plot(xs, st[agent_type + \"_m\"][-int(100 / batch_size):], color=colors[agent_type],\n",
    "                                  linewidth=4 if agent_type == \"self_class\" else 1,\n",
    "                                  label=label_dict[agent_type])\n",
    "                    ax.fill_between(xs, st[agent_type + \"_m\"][-int(100 / batch_size):] - st[agent_type + \"_se\"][\n",
    "                                                                                         -int(100 / batch_size):],\n",
    "                                    st[agent_type + \"_m\"][-int(100 / batch_size):] + st[agent_type + \"_se\"][\n",
    "                                                                                     -int(100 / batch_size):],\n",
    "                                    alpha=0.08, color=colors[agent_type])\n",
    "                else:\n",
    "                    if agent_type == \"self_class\":\n",
    "                        r_l = ax.plot(xs, st[agent_type + \"_m\"], color=colors[agent_type], linewidth=4 if only_first_100 or last_100 else 2,\n",
    "                                  label=label_dict[agent_type])\n",
    "                    else:\n",
    "                        r_l = ax.plot(xs, st[agent_type + \"_m\"], color=colors[agent_type], linewidth=1,\n",
    "                                  label=label_dict[agent_type])\n",
    "                    ax.fill_between(xs, st[agent_type + \"_m\"] - st[agent_type + \"_se\"],\n",
    "                                    st[agent_type + \"_m\"] + st[agent_type + \"_se\"], alpha=0.08,\n",
    "                                    color=colors[agent_type])\n",
    "            else:  # Human\n",
    "                xs = [int(i * batch_size) for i in range(0, len(st[\"human_m\"]))]\n",
    "                if last_100:\n",
    "                    hum_l = ax.plot(xs, st['human_m'], color=colors[agent_type], linewidth=4,\n",
    "                                    label=label_dict['human'], linestyle='dashed', zorder=9999)\n",
    "                else:\n",
    "                    hum_l = ax.plot(xs, st['human_m'], color=colors[agent_type], linewidth=4,\n",
    "                                    label=label_dict['human'], zorder=9999)\n",
    "                x = [int(i * batch_size) for i in range(0, len(st[\"human_m\"]))]\n",
    "                ax.fill_between(x, st['human_m'] - st['human_se'],\n",
    "                                st['human_m'] + st['human_se'],\n",
    "                                alpha=0.08, color=colors[agent_type])\n",
    "    plt.tight_layout()\n",
    "    if combined:\n",
    "        plt.axvline(x=2000, color=\"#ffff03\", alpha=0.2, linewidth=15)\n",
    "\n",
    "    #leg = plt.legend(bbox_to_anchor=(1, 1), loc='upper left', title_fontsize=25)\n",
    "    #plt.rc('legend', fontsize=25)\n",
    "\n",
    "    #for legobj in leg.legendHandles:\n",
    "    #    legobj.set_linewidth(6.0)\n",
    "\n",
    "    # For plotting bayes lines\n",
    "    bfs = {\n",
    "        'logic_game': [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
    "                       1, 0, 1, 1, 1\n",
    "            , 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
    "                       1, 1\n",
    "            , 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0],\n",
    "        'contingency_game': [1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
    "                             0, 1, 1, 0, 0, 0, 1\n",
    "            , 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
    "                             0, 1\n",
    "            , 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1\n",
    "                             ],\n",
    "        'change_agent_game': [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
    "                              1, 1, 1, 1, 1, 1, 1\n",
    "            , 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "                              1, 1\n",
    "            , 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        'contingency_game_shuffled_1': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "            , 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                                        0, 0\n",
    "            , 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
    "\n",
    "\n",
    "    if only_first_100:\n",
    "        bf = bfs[game_type]\n",
    "        for x, s in enumerate(bf):\n",
    "            if s == 1:\n",
    "                if game_type == \"logic_game\":\n",
    "                    ax.hlines(xmin=x, xmax=x + 1, y=17, linewidth=12, color=\"#0373fc\")\n",
    "                elif game_type == \"contingency_game\":\n",
    "                    ax.hlines(xmin=x, xmax=x + 1, y=45, linewidth=12, color=\"#0373fc\")\n",
    "                elif game_type == \"change_agent_game\":\n",
    "                    ax.hlines(xmin=x, xmax=x + 1, y=150, linewidth=12, color=\"#0373fc\")\n",
    "                elif game_type == \"contingency_game_shuffled_1\":\n",
    "                    ax.hlines(xmin=x, xmax=x + 1, y=45, linewidth=12, color=\"#0373fc\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    path = './plots/{}/'.format(game_type)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # Human vs. Self\n",
    "    hs = ''\n",
    "    if len(agent_types) == 2:\n",
    "        hs = '_human_vs_self'\n",
    "\n",
    "    fig.savefig(\n",
    "        path + 'effiency_curves_' + game_type + '{}{}{}{}{}.pdf'.format('_' + str(batch_size),\n",
    "                                                                        '_first_100' if only_first_100 else '',\n",
    "                                                                        '_last_100' if last_100 else '',\n",
    "                                                                        '_combined' if combined else '',\n",
    "                                                                        hs),\n",
    "        format='pdf',\n",
    "        bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "# Append stats of two data (normal + extended)\n",
    "def append_stats(dict_normal, dict_ext, game_types, game_types_ext):\n",
    "    appended_data = {}\n",
    "    for i, game in enumerate(game_types):\n",
    "        appended_data[game] = {}\n",
    "        for key, value in dict_normal[game].items():\n",
    "            data_normal = dict_normal[game][key]\n",
    "            data_ext = dict_ext[game_types_ext[i]][key]\n",
    "            appended_data[game][key] = np.concatenate((data_normal, data_ext))\n",
    "\n",
    "    return appended_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "game_types = [\"logic_game\", \"contingency_game\", \"change_agent_game\"] # \"change_agent_extended_2_game\"\n",
    "agent_types = [\"human\", \"self_class\", \"random\", \"a2c_training\", \"trpo_training\", \"acer_training\", \"ppo2_training\",\n",
    "               \"dqn_training\", ]\n",
    "\n",
    "batch_size = 20\n",
    "for game in game_types:\n",
    "    stats_dict, game_types, agent_types, batch_size = get_performance([game], agent_types,\n",
    "                                                                      batch_size, single_seed=False)\n",
    "    # All 2000\n",
    "    plotter(stats_dict, game_types, agent_types, batch_size)\n",
    "\n",
    "    # Last Hundred\n",
    "    plotter(stats_dict, game_types, [\"self_class\", \"a2c_training\", \"trpo_training\", \"acer_training\", \"ppo2_training\", \"dqn_training\"], batch_size, last_100=True)\n",
    "\n",
    "    # First Hundred\n",
    "    if game == 'change_agent_game':\n",
    "        plotter(get_performance([game], [\"human\", \"self_class\"], 5, single_seed=False)[0], [game], [\"human\", \"self_class\"], 5, only_first_100=True)\n",
    "    else:\n",
    "        plotter(get_performance([game], [\"human\", \"self_class\"], 5, single_seed=False)[0], [game], [\"human\", \"self_class\"], 5, only_first_100=True)\n",
    "\n",
    "    plotter(get_performance([game], [\"human\", \"self_class\"], 1, single_seed=False)[0], [game], [\"human\", \"self_class\"], 1, only_first_100=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Plot Shuffled Key Mappings\n",
    "game_types = [\"contingency_game_shuffled_100\", \"contingency_game_shuffled_200\"]\n",
    "agent_types = [\"self_class\", \"a2c_training\", \"trpo_training\", \"acer_training\", \"ppo2_training\",\n",
    "               \"dqn_training\", \"random\"]\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "for game in game_types:\n",
    "    stats_dict, game_types, agent_types, batch_size = get_performance([game], agent_types,\n",
    "                                                                      batch_size, single_seed=False)\n",
    "\n",
    "    plotter(stats_dict, game_types, agent_types, batch_size, False, last_100=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Plot stress tests\n",
    "game_types = [\"logic_game\", \"contingency_game\", \"change_agent_game\"]\n",
    "extended_game_types = [\"logic_game_extended\", \"contingency_game_extended\", \"change_agent_extended_game\"]\n",
    "for i, game in enumerate(game_types):\n",
    "    agent_types_ext = [\"a2c_training\", \"trpo_training\", \"acer_training\", \"ppo2_training\",\n",
    "                       \"dqn_training\"]\n",
    "    stats_dict, _, _, _ = get_performance([game], agent_types_ext,\n",
    "                                          batch_size=20, single_seed=False)\n",
    "    stats_dict_ext, _, agent_types_ext, batch_size_ext = get_performance(\n",
    "        [extended_game_types[i]], agent_types_ext, batch_size=20, single_seed=False)\n",
    "\n",
    "    appended_stats = append_stats(stats_dict, stats_dict_ext, [game], [extended_game_types[i]])\n",
    "\n",
    "    plotter(appended_stats, [game], agent_types_ext, batch_size=20, combined=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## ----- Plot the number of steps the player takes before any agent moves from its starting location\n",
    "\n",
    "# Plot no-movement action count of agent for each level\n",
    "def plot_nm_ac(game_types, agent_types, batch_size=20, only_first_100=False):\n",
    "    for i, game_type in enumerate(game_types):\n",
    "        nm_ac = get_all_nm_ac(agent_types, game_type, batch_size)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "        ax.xaxis.label.set_size(25)\n",
    "        ax.yaxis.label.set_size(25)\n",
    "\n",
    "        if only_first_100:\n",
    "            ax.set_xlim([0, 100])\n",
    "\n",
    "        ax.set_xlabel(xlabel=\"Levels Played\", labelpad=21)\n",
    "\n",
    "        ax.set_ylabel(ylabel=\"No. Steps Until Self Orienting\\nAveraged Every {} Levels\".format(batch_size),\n",
    "                      labelpad=21)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=30)\n",
    "\n",
    "        for j, agent in enumerate(agent_types):\n",
    "            xs = [int(i * batch_size) for i in range(0, len(nm_ac[agent + \"_m\"]))]\n",
    "            line_width = 3 if agent == 'human' else 1\n",
    "            ax.plot(xs, nm_ac[agent + \"_m\"], color=colors[agent], linewidth=line_width, label=label_dict[agent])\n",
    "            upper_curve = [nm_ac[agent + '_m'][i] + nm_ac[agent + '_se'][i] for i in\n",
    "                           range(len(nm_ac[agent + '_m']))]\n",
    "            lower_curve = [nm_ac[agent + '_m'][i] - nm_ac[agent + '_se'][i] for i in\n",
    "                           range(len(nm_ac[agent + '_m']))]\n",
    "            x = [int(i * batch_size) for i in range(0, len(nm_ac[agent + \"_m\"]))]\n",
    "            ax.fill_between(x, lower_curve, upper_curve, alpha=0.05, color=colors[agent])\n",
    "\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        #plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize='xx-large')\n",
    "\n",
    "        fs = 50 if 'contingency_game' in game_type else 25\n",
    "        fs = 100 if 'contingency_game_shuffled' in game_type else fs\n",
    "\n",
    "        #leg = plt.legend(bbox_to_anchor=(1, 1), loc='upper left', title_fontsize=fs)\n",
    "        #plt.rc('legend', fontsize=fs)\n",
    "\n",
    "        #for legobj in leg.legendHandles:\n",
    "        #    legobj.set_linewidth(6.0)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        path = './plots/{}/{}/'.format(game_type, 'curves')\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        fig.savefig(path + 'no_movement_action_count_{}{}.pdf'.format(game_type, batch_size), format='pdf')\n",
    "\n",
    "\n",
    "## Get no-movement action count of agent for each level and each game as a dictionary\n",
    "def get_all_nm_ac(agent_types, game_type, batch_size):\n",
    "    stats = {}\n",
    "    for agent in agent_types:\n",
    "        stats[agent + \"_m\"], stats[agent + \"_se\"] = get_nm_ac(agent, game_type, batch_size)\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "## Get no-movement action count of agent for each level\n",
    "def get_nm_ac(agent_type, game_type, batch_size):\n",
    "    files = glob.glob(\"../data/\" + game_type + \"/\" + agent_type + \"/*/*.json\")\n",
    "\n",
    "    if len(files) == 0:\n",
    "        files = glob.glob(\"../data/\" + game_type + \"/\" + agent_type + \"/*.json\")\n",
    "\n",
    "    all_seeds = []\n",
    "    curr_seed = []\n",
    "    seed = 0\n",
    "    curr_file_count = 0\n",
    "    file_amt = len(files)\n",
    "\n",
    "    def get_seed_num_and_iter(x):\n",
    "        return int(x.split(\"/\")[4][4]) * 1000000000 + int(x.split(\"/\")[-1][6:-5])\n",
    "\n",
    "    sorted_files = sorted(files, key=os.path.getmtime if agent_type == 'human' else get_seed_num_and_iter)\n",
    "    for i, file in enumerate(sorted_files):\n",
    "        data = json.load(open(file))\n",
    "        self_locs = data.get(\"data\")[\"self_locs\"]\n",
    "\n",
    "        level_amt = 100\n",
    "        action_count = [1] * level_amt\n",
    "\n",
    "        # In each 100 levels:\n",
    "        for level in range(level_amt):\n",
    "            if len(self_locs[level]) == 0:\n",
    "                continue\n",
    "            action_amt = len(self_locs[level][0])\n",
    "            for i in range(action_amt):\n",
    "                if i == level_amt:\n",
    "                    break\n",
    "\n",
    "                x = self_locs[level][0][i]\n",
    "                y = self_locs[level][1][i]\n",
    "                x1 = self_locs[level][0][i + 1]\n",
    "                y1 = self_locs[level][1][i + 1]\n",
    "\n",
    "                if x == x1 and y == y1:  # Still in the same position\n",
    "                    action_count[level] = action_count[level] + 1\n",
    "                else:  # Position have changed\n",
    "                    break\n",
    "\n",
    "        curr_file_count += 1\n",
    "        curr_seed.append(action_count)\n",
    "\n",
    "        if agent_type == 'human' and (curr_file_count == file_amt or file_amt == 1):\n",
    "            all_seeds = curr_seed\n",
    "            break\n",
    "\n",
    "        if agent_type != 'human' and curr_file_count == 20:\n",
    "            all_seeds.append(curr_seed)\n",
    "            curr_seed = []\n",
    "            curr_file_count = 0\n",
    "            seed += 1\n",
    "\n",
    "    all_seeds = pd.DataFrame(all_seeds)\n",
    "\n",
    "    seed_average = []\n",
    "    seed_sem = []\n",
    "    for column in all_seeds:\n",
    "        seed_average.append(np.mean(list(all_seeds[column]), axis=0))\n",
    "        seed_sem.append((pd.DataFrame(list(all_seeds[column]))).sem(axis=0))\n",
    "\n",
    "    curr_avg_data = pd.DataFrame(seed_average).T\n",
    "    curr_sem_data = pd.DataFrame(seed_sem).T\n",
    "\n",
    "    if agent_type != 'human':\n",
    "        seed_mean = np.array(\n",
    "            [curr_avg_data[column].groupby(curr_avg_data.index // batch_size).mean() for column in\n",
    "             curr_avg_data]).reshape(\n",
    "            int(curr_avg_data.shape[1] * 100 * 1 / batch_size))\n",
    "        s_sem = np.array(\n",
    "            [curr_sem_data[column].groupby(curr_sem_data.index // batch_size).mean() for column in\n",
    "             curr_sem_data]).reshape(\n",
    "            int(curr_sem_data.shape[1] * 100 * 1 / batch_size))\n",
    "    else:\n",
    "        temp = np.asarray(curr_avg_data).T\n",
    "        avg_ma = [temp[i:i + batch_size].mean() for i in range(0, curr_avg_data.shape[1] - batch_size + 1, batch_size)]\n",
    "\n",
    "        temp = np.asarray(curr_sem_data).T\n",
    "        avg_se = [temp[i:i + batch_size].mean() for i in range(0, curr_sem_data.shape[1] - batch_size + 1, batch_size)]\n",
    "\n",
    "        seed_mean = np.array(avg_ma).reshape(int(curr_avg_data.shape[1] / batch_size))\n",
    "        s_sem = np.array(avg_se).reshape(int(curr_sem_data.shape[1] / batch_size))\n",
    "\n",
    "    return seed_mean, s_sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Plot Action Counts Without Movement\n",
    "\n",
    "agent_types = [\"human\", \"self_class\", \"random\", \"a2c_training\", \"trpo_training\", \"acer_training\", \"ppo2_training\",\n",
    "               \"dqn_training\", ]\n",
    "game_types = [\"logic_game\"]\n",
    "plot_nm_ac(game_types, agent_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## ----- Plot average distance from the goal for each level\n",
    "def plot_avg_distance(game_types, agent_types, batch_size=50, level=1999):\n",
    "    for i, game_type in enumerate(game_types):\n",
    "        avg_distance = get_all_avg_distance(agent_types, game_type, batch_size, level)\n",
    "        xls = [150]\n",
    "        for xl in xls:\n",
    "            fig, ax = plt.subplots(figsize=(20, 10))\n",
    "            ax.set_xlim([0, xl])\n",
    "            ax.xaxis.label.set_size(25)\n",
    "            ax.yaxis.label.set_size(25)\n",
    "\n",
    "            ax.set_xlabel(xlabel=\"Step\", labelpad=21)\n",
    "            #ax.set_ylabel(ylabel=\"Average Distance to Goal\", labelpad=21)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=17)\n",
    "            ax.xaxis.set_tick_params(labelsize=25)\n",
    "            ax.yaxis.set_tick_params(labelsize=25)\n",
    "            #ax.set_title(game_titles[game_type], fontweight='bold', fontsize=25)\n",
    "\n",
    "            for j, agent in enumerate(agent_types):\n",
    "                xs = [int(i * batch_size) for i in range(0, len(avg_distance[agent + \"_m\"]))]\n",
    "                line_width = 4 if agent == 'human' or agent == 'self_class' else 1\n",
    "                ax.plot(xs, avg_distance[agent + \"_m\"], color=colors[agent], linewidth=line_width,\n",
    "                        label=label_dict[agent])\n",
    "                upper_curve = [avg_distance[agent + '_m'][i] + avg_distance[agent + '_se'][i] for i in\n",
    "                               range(len(avg_distance[agent + '_m']))]\n",
    "                lower_curve = [avg_distance[agent + '_m'][i] - avg_distance[agent + '_se'][i] for i in\n",
    "                               range(len(avg_distance[agent + '_m']))]\n",
    "                x = [int(i * batch_size) for i in range(0, len(avg_distance[agent + \"_m\"]))]\n",
    "                ax.fill_between(x, lower_curve, upper_curve, alpha=0.08, color=colors[agent])\n",
    "\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            ax.spines['top'].set_visible(False)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            path = './plots/{}/{}/'.format(game_type, 'curves')\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "\n",
    "            fig.savefig(path + '{}_distance_{}{}{}.pdf'.format(xl, game_type, batch_size, level), format='pdf')\n",
    "\n",
    "\n",
    "def get_all_avg_distance(agent_types, game_type, batch_size, level=0):\n",
    "    stats = {}\n",
    "    for agent in agent_types:\n",
    "        print(agent + \"_m\")\n",
    "        stats[agent + \"_m\"], stats[agent + \"_se\"] = get_avg_distance(agent, game_type, batch_size, level)\n",
    "\n",
    "    return stats\n",
    "\n",
    "# Ignore batch_size here, as it does not mean anything\n",
    "def get_avg_distance(agent_type, game_type, batch_size, level=0):\n",
    "    if batch_size != 1:\n",
    "        print(\"Batch size should be 1\")\n",
    "        return\n",
    "    files = glob.glob(\"../data/\" + game_type + \"/\" + agent_type + \"/*/*.json\")\n",
    "\n",
    "    if len(files) == 0:\n",
    "        files = glob.glob(\"../data/\" + game_type + \"/\" + agent_type + \"/*.json\")\n",
    "\n",
    "    all_seeds = []\n",
    "    curr_file_count = 0\n",
    "\n",
    "    def get_seed_num_and_iter(x):\n",
    "        return int(x.split(\"/\")[4][4]) * 1000000000 + int(x.split(\"/\")[-1][6:-5])\n",
    "\n",
    "    sorted_files = sorted(files, key=os.path.getmtime if agent_type == 'human' else get_seed_num_and_iter)\n",
    "\n",
    "    # Get the files that only contain the last level\n",
    "    if agent_type != 'human':\n",
    "        sorted_files = [sorted_files[j] for j in range(0, 200, 20)]  # TODO: Debug!\n",
    "\n",
    "    file_amt = len(sorted_files)\n",
    "    level = level % 100\n",
    "\n",
    "    # For each seed/subject:\n",
    "    for i, file in enumerate(sorted_files):\n",
    "        data = json.load(open(file))\n",
    "        self_locs = data.get(\"data\")[\"self_locs\"]\n",
    "\n",
    "        #level_amt = 100\n",
    "        action_amt = len(self_locs[level][0])\n",
    "\n",
    "        # Store distance to goal at every action for a particular seed\n",
    "        distances = [0 for y in range(action_amt)]\n",
    "\n",
    "        if len(self_locs[level]) == 0:\n",
    "            continue\n",
    "\n",
    "        # In each action:\n",
    "        for action_index in range(action_amt):\n",
    "            x = self_locs[level][0][action_index]\n",
    "            y = self_locs[level][1][action_index]\n",
    "\n",
    "            distances[action_index] = abs(x - 10) + abs(y - 10)\n",
    "\n",
    "        curr_file_count += 1\n",
    "        all_seeds.append(distances)\n",
    "\n",
    "    all_seeds = pd.DataFrame(all_seeds).fillna(0)\n",
    "\n",
    "    if agent_type == 'human':\n",
    "        all_seeds.insert(loc=0, value=pd.DataFrame([8 for i in range(file_amt)]), column=-1)  # Set starting distance (8)\n",
    "\n",
    "    seed_average = []\n",
    "    seed_sem = []\n",
    "    for column in all_seeds:\n",
    "        seed_average.append(np.mean(list(all_seeds[column]), axis=0))\n",
    "        seed_sem.append((pd.DataFrame(list(all_seeds[column]))).sem(axis=0))\n",
    "\n",
    "    curr_avg_data = pd.DataFrame(seed_average).T\n",
    "    curr_sem_data = pd.DataFrame(seed_sem).T\n",
    "\n",
    "    if agent_type != 'human':  # AI\n",
    "        seed_mean = np.array(\n",
    "            [curr_avg_data[column].groupby(curr_avg_data.index // batch_size).mean() for column in\n",
    "             curr_avg_data]).reshape(\n",
    "            int(curr_avg_data.shape[1] * 1 / batch_size))\n",
    "        s_sem = np.array(\n",
    "            [curr_sem_data[column].groupby(curr_sem_data.index // batch_size).mean() for column in\n",
    "             curr_sem_data]).reshape(\n",
    "            int(curr_sem_data.shape[1] * 1 / batch_size))\n",
    "    else:\n",
    "        temp = np.asarray(curr_avg_data).T\n",
    "        avg_ma = [temp[i:i + batch_size].mean() for i in range(0, curr_avg_data.shape[1] - batch_size + 1, batch_size)]\n",
    "\n",
    "        temp = np.asarray(curr_sem_data).T\n",
    "        avg_se = [temp[i:i + batch_size].mean() for i in range(0, curr_sem_data.shape[1] - batch_size + 1, batch_size)]\n",
    "\n",
    "        seed_mean = np.array(avg_ma).reshape(int(curr_avg_data.shape[1] / batch_size))\n",
    "        s_sem = np.array(avg_se).reshape(int(curr_sem_data.shape[1] / batch_size))\n",
    "\n",
    "    return seed_mean, s_sem"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent_types = [\"human\", \"self_class\", \"random\", \"a2c_training\", \"trpo_training\", \"acer_training\", \"ppo2_training\",\n",
    "               \"dqn_training\", ]\n",
    "game_types = [\"contingency_game\", \"contingency_game_shuffled_1\", \"change_agent_game\", \"contingency_game_shuffled_100\", \"contingency_game_shuffled_200\"]\n",
    "plot_avg_distance(game_types, agent_types, batch_size=1, level=1)\n",
    "plot_avg_distance(game_types, agent_types, batch_size=1, level=1999)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}