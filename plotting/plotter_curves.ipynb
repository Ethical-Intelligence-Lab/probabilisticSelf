{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from os.path import exists\n",
    "import pickle\n",
    "from scipy.stats import sem\n",
    "import statistics\n",
    "\n",
    "colors = {\"human\": \"#000000\", \"data_sf\": \"#8a3a01\", \"human_extended\": \"#525151\", \"self_class\": \"#19c202\", \"self_class_include_perturbation\": \"#19c202\",\n",
    "          \"keep_close\": \"#0f7801\", \"self_classshort\": \"#19c202\",\n",
    "          \"random\": \"#9c2200\", \"a2c_training\": \"#89CFF0\",\n",
    "          \"trpo_training\": \"#0000FF\",\n",
    "          \"acer_training\": \"#7393B3\", \"ppo2_training\": \"#0096FF\", \"dqn_training\": \"#5D3FD3\", \"option_critic\": \"#23dedb\"}\n",
    "\n",
    "game_titles = {\n",
    "    \"shuffleKeys_game\": \"Switching Mappings Keys Game\",\n",
    "    \"shuffleKeys_game_final\": \"Switching Mappings Keys Game\",\n",
    "    \"contingency_game\": \"Contingency Game\",\n",
    "    \"contingency_game_final\": \"Contingency Game\",\n",
    "    \"contingency_game_0\": \"Contingency Game (Single Seed)\",\n",
    "    \"contingency_game_lrtest\": \"Contingency Game (Single Seed)\",\n",
    "    \"contingency_game_r0\": \"Contingency Game (Agent Placement is Constant Among Each Level)\",\n",
    "    \"contingency_game_diff_color\": \"Contingency Game (Real Agent is Blue)\",\n",
    "    \"contingency_game_shuffled\": \"Switching Mappings Game (Switched Once in Every 200 Levels)\",\n",
    "    \"contingency_game_shuffled_1\": \"Switching Mappings Game (Switched Every Level)\",\n",
    "    \"contingency_game_shuffled_100\": \"Switching Mappings Game (Switched Once in Every 100 Levels)\",\n",
    "    \"contingency_game_shuffled_200\": \"Switching Mappings Game (Switched Once in Every 200 Levels)\",\n",
    "    \"contingency_game_shuffled_final\": \"Switching Mappings Game (Switched Once in Every 200 Levels)\",\n",
    "    \"contingency_game_shuffled_1_final\": \"Switching Mappings Game (Switched Every Level)\",\n",
    "    \"contingency_game_shuffled_100_final\": \"Switching Mappings Game (Switched Once in Every 100 Levels)\",\n",
    "    \"contingency_game_shuffled_200_final\": \"Switching Mappings Game (Switched Once in Every 200 Levels)\",\n",
    "    \"logic_game\": \"Logic Game\",\n",
    "    \"logic_game_final\": \"Logic Game\",\n",
    "    \"logic_game_0\": \"Logic Game\",\n",
    "    \"logic_game_lrtest\": \"Logic Game\",\n",
    "    \"logic_include_perturbation_game\": \"Logic Game (Modified After 2000 Levels)\",\n",
    "    \"change_agent_game\": \"Switching Embodiments Game\",\n",
    "    \"change_agent_game_final\": \"Switching Embodiments Game\",\n",
    "    \"change_agent_game_lrtest\": \"Switching Embodiments Game (Single Seed)\"\n",
    "}\n",
    "\n",
    "label_dict = {'human': 'Human', 'data_sf': 'Human (Self-Finding)', 'human_extended': 'Human include_perturbation',\n",
    "              'self_class': 'Self Class', 'self_class_include_perturbation': 'Self Class', 'self_classshort': 'Self Class', 'dqn_training': 'DQN',\n",
    "              'random': 'Random', 'a2c_training': \"A2C\", 'trpo_training': 'TRPO', 'ppo2_training': 'PPO2',\n",
    "              'acer_training': 'ACER', \"option_critic\": \"OC\", \"keep_close\": \"Keeping Close\"}\n",
    "\n",
    "\n",
    "def find_between(s, first, last):\n",
    "    try:\n",
    "        start = s.index(first) + len(first)\n",
    "        end = s.index(last, start)\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def get_seed_num_and_iter(x):\n",
    "    if \"seed\" in x:\n",
    "        return int(find_between(x.split(\"/\")[4], \"seed\", \"-\")) * 1000000000 + int(x.split(\"/\")[-1][6:-5])\n",
    "    else:\n",
    "        if \"short\" in x:\n",
    "            return int(x.split(\"/\")[4].split(\"iter\")[1]) * 1000000000 + int(x.split(\"/\")[-1][11:-5])\n",
    "        else:\n",
    "            return int(x.split(\"/\")[4].split(\"iter\")[1]) * 1000000000 + int(x.split(\"/\")[-1][6:-5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def cosmetic_change(game_type, ax, axes, last_100, agent_types, only_first_100, perturbated, avg_per_n_steps):\n",
    "    if game_type == 'contingency_game_shuffled':\n",
    "        axes.set_ylim([0, 6000])\n",
    "    elif game_type == 'change_agent_game':\n",
    "        axes.set_ylim([0, 750])\n",
    "    elif game_type in ['contingency_game', 'contingency_game_diff_color', 'contingency_game_0',\n",
    "                       ]:\n",
    "        if not last_100:\n",
    "            axes.set_ylim([0, 800])\n",
    "    elif game_type == \"contingency_game_shuffled_200\":\n",
    "        axes.set_ylim([0, 4000])\n",
    "    elif game_type in [\"contingency_game_shuffled_100\", \"contingency_game_shuffled_1\"]:\n",
    "        axes.set_ylim([0, 6000])\n",
    "        if game_type == \"contingency_game_shuffled_1\" and last_100:\n",
    "            axes.set_ylim([0, 2000])\n",
    "    elif game_type == 'logic_game':\n",
    "        axes.set_ylim([0, 100])\n",
    "\n",
    "    if perturbated and game_type in ['contingency_game']:\n",
    "        axes.set_ylim([0, 600])\n",
    "\n",
    "    if only_first_100 and ((\"self_class\" in agent_types) and (\"human\" in agent_types)):\n",
    "        axes.set_xlim([0, 120])\n",
    "        axes.set_ylim([0, 13]) if game_type == 'logic_game' else axes.set_ylim([0, 50])\n",
    "        if game_type == \"change_agent_game\":\n",
    "            axes.set_ylim([0, 160])\n",
    "\n",
    "    if only_first_100:\n",
    "        axes.set_xlim([0, 100])\n",
    "            \n",
    "\n",
    "    if only_first_100 and perturbated:\n",
    "        if game_type == \"change_agent_game\":\n",
    "            axes.set_xlim([0, 30])\n",
    "        else:\n",
    "            axes.set_xlim([0, 150])\n",
    "\n",
    "    if last_100 and game_type == \"contingency_game\":\n",
    "        axes.set_ylim([0, 50])\n",
    "    elif last_100 and game_type == \"change_agent_game\":\n",
    "        axes.set_ylim([0, 160])\n",
    "    elif only_first_100 and game_type in [\"change_agent_game\", \"change_agent_game_harder\"] and perturbated:\n",
    "        axes.set_ylim([0, 325])\n",
    "    elif last_100 and game_type == \"contingency_game_shuffled_100\":\n",
    "        axes.set_ylim([0, 2500])\n",
    "    elif (only_first_100 or last_100) and game_type == \"logic_game\":\n",
    "        axes.set_ylim([0, 20])\n",
    "    elif only_first_100 and game_type == 'contingency_game':\n",
    "        axes.set_ylim([0, 50])\n",
    "\n",
    "    y_str = \"No. Steps To Complete Level\" + '\\nAveraged Every {} Levels'.format(avg_per_n_steps)\n",
    "    if avg_per_n_steps == 1:\n",
    "        y_str = \"No. Steps To Complete Level\"\n",
    "\n",
    "    if game_type == \"contingency_game_shuffled_1\" and only_first_100:\n",
    "        axes.set_ylim([0, 50])\n",
    "\n",
    "    if not only_first_100 and not last_100:\n",
    "        ax.set_ylabel(ylabel=y_str, labelpad=21, fontsize=25)\n",
    "        ax.set_xlabel(xlabel=\"Levels Played\", labelpad=21, fontsize=25)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=27)\n",
    "    else:\n",
    "        ax.tick_params(axis='both', which='major', labelsize=40)\n",
    "\n",
    "# avg_per_n_steps = Average per N levels\n",
    "# single_seed=True plots only a single seed (For testing)\n",
    "def get_performance(game_type, agent_types, avg_per_n_steps=10, single_seed=False, include_perturbation=False):\n",
    "    game_types = [game_type]\n",
    "    param_dict = {}; param_dict[game_type] = {}\n",
    "    \n",
    "    # Check if saved data exists\n",
    "    loaded = {}\n",
    "    for agent_type in agent_types:\n",
    "        loaded[agent_type] = False\n",
    "        fpath = './plotting_data/{}_'.format(game_type) + agent_type + \"{}\".format(\"_ext\" if include_perturbation else \"\") + \".pickle\"\n",
    "        if exists(fpath):\n",
    "            loaded[agent_type] = True\n",
    "            param_dict[game_type][agent_type] = pickle.load(open(fpath, 'rb'))\n",
    "            print(\"Loaded {}...\".format(agent_type))\n",
    "        else:\n",
    "            print(\"Will read {}...\".format(agent_type))\n",
    "            \n",
    "\n",
    "    if include_perturbation:\n",
    "        target_file_count = 40\n",
    "    else:\n",
    "        target_file_count = 20\n",
    "\n",
    "    target_file_count_o = target_file_count\n",
    "\n",
    "    ## ----- Read in data\n",
    "    for agent_type in agent_types:\n",
    "        if agent_type == \"self_classshort\":\n",
    "            target_file_count = 2\n",
    "        else:\n",
    "            target_file_count = target_file_count_o\n",
    "\n",
    "        if loaded[agent_type]:\n",
    "            continue\n",
    "\n",
    "        files_o = glob.glob(\"../data/\" + game_type + \"/\" + agent_type + \"/*/*.json\")\n",
    "        if len(files_o) == 0:\n",
    "            files_o = glob.glob(\"../data/\" + game_type + \"/\" + agent_type + \"/*.json\")\n",
    "\n",
    "        files = files_o\n",
    "        # Skip stress test files\n",
    "        if not include_perturbation and agent_type not in [\"human\", \"data_sf\", \"human_extended\", \"random\"]:\n",
    "            files = []\n",
    "            for x in files_o:\n",
    "                if 'short' in x:\n",
    "                    if int(x.split(\"/\")[-1][11:-5]) <= 1900:\n",
    "                        files.append(x)\n",
    "\n",
    "                else:\n",
    "                    if int(x.split(\"/\")[-1][6:-5]) <= 1900:\n",
    "                        files.append(x)\n",
    "\n",
    "        seed = 0\n",
    "        curr_file_count = 0\n",
    "        file_amt = len(files)\n",
    "        param_dict[game_type][agent_type] = {}\n",
    "        seed_current = []\n",
    "        all_seeds = []\n",
    "        seed_total = 20 if not single_seed else 1\n",
    "\n",
    "        if game_type in ['change_agent_game', 'change_agent_game_harder']:\n",
    "            seed_total = 18\n",
    "\n",
    "        if game_type in ['contingency_game_shuffled_100', 'contingency_game_shuffled_200']:\n",
    "            seed_total = 10\n",
    "\n",
    "        sorted_files = sorted(files, key=os.path.getmtime if agent_type in ['human', 'data_sf',\n",
    "                                                                            'human_extended'] else get_seed_num_and_iter)\n",
    "        for i, file in enumerate(sorted_files):\n",
    "            with open(file, 'r') as fp:\n",
    "                print(\"Getting \", file, \"...\")\n",
    "                data = json.load(fp)\n",
    "                param_dict[game_type][agent_type] = data['data']['steps']\n",
    "                curr_file_count += 1\n",
    "\n",
    "                seed_current.append(data['data']['steps'])\n",
    "\n",
    "                if agent_type in ['human', 'data_sf', 'human_extended'] and (file_amt == 1 or single_seed):\n",
    "                    param_dict[game_type][agent_type] = [data['data']['steps']]\n",
    "                    break\n",
    "                else:\n",
    "                    if agent_type in ['human', 'data_sf', 'human_extended'] and curr_file_count == file_amt:\n",
    "                        param_dict[game_type][agent_type] = seed_current\n",
    "                        break\n",
    "\n",
    "                if agent_type != 'human' and curr_file_count == target_file_count:\n",
    "                    all_seeds.append(seed_current)\n",
    "                    seed_current = []\n",
    "                    curr_file_count = 0\n",
    "                    seed += 1\n",
    "\n",
    "                if seed == seed_total:\n",
    "                    print(\"Seed total: \", seed)\n",
    "                    print(\"Saving\")\n",
    "                    param_dict[game_type][agent_type] = all_seeds\n",
    "                    all_seeds = []\n",
    "\n",
    "                    if single_seed:\n",
    "                        break\n",
    "\n",
    "        # Save data of current agent\n",
    "        with open('./plotting_data/{}_'.format(game_type) + agent_type + \"{}\".format(\"_ext\" if include_perturbation else \"\") + \".pickle\", 'wb') as f:\n",
    "            print(\"Saving {}...\".format(agent_type)); pickle.dump(param_dict[game_type][agent_type], f)\n",
    "        print(\"Passing from {} to Next agent\".format(agent_type))\n",
    "\n",
    "    ## ---- Get descriptive statistics\n",
    "    stats_dict = {}\n",
    "    stats_dict[game_type] = {}\n",
    "    for agent_type in agent_types:\n",
    "        print(agent_type)\n",
    "        raw_data = pd.DataFrame(param_dict[game_type][agent_type])\n",
    "\n",
    "        seed_average = []\n",
    "        seed_sem = []\n",
    "        for column in raw_data:\n",
    "            seed_average.append(np.mean(list(raw_data[column]), axis=0))\n",
    "            seed_sem.append((pd.DataFrame(list(raw_data[column]))).sem(axis=0))\n",
    "\n",
    "        curr_avg_data = pd.DataFrame(seed_average).T\n",
    "        curr_sem_data = pd.DataFrame(seed_sem).T\n",
    "        stats_dict[game_type][agent_type] = raw_data\n",
    "\n",
    "        if agent_type not in ['human', 'data_sf', 'human_extended']:  # Average per N levels for AI\n",
    "            stats_dict[game_type][agent_type + \"_m\"] = np.array(\n",
    "                [curr_avg_data[column].groupby(curr_avg_data.index // avg_per_n_steps).mean() for column in\n",
    "                    curr_avg_data]).reshape(\n",
    "                int(curr_avg_data.shape[1] * 100 * 1 / avg_per_n_steps))\n",
    "            stats_dict[game_type][agent_type + \"_se\"] = np.array(\n",
    "                [curr_sem_data[column].groupby(curr_sem_data.index // avg_per_n_steps).mean() for column in\n",
    "                    curr_sem_data]).reshape(\n",
    "                int(curr_sem_data.shape[1] * 100 * 1 / avg_per_n_steps))\n",
    "        else:  # Average per N levels for Human data\n",
    "            if agent_type in ['human', 'human_extended'] and include_perturbation and avg_per_n_steps != 1:\n",
    "                c_avg_per_n_steps = 1\n",
    "            else:\n",
    "                c_avg_per_n_steps = avg_per_n_steps\n",
    "            temp = np.asarray(curr_avg_data).T\n",
    "            avg_ma = [temp[i:i + c_avg_per_n_steps].mean() for i in\n",
    "                        range(0, curr_avg_data.shape[1] - c_avg_per_n_steps + 1, c_avg_per_n_steps)]\n",
    "\n",
    "            temp = np.asarray(curr_sem_data).T\n",
    "            avg_se = [temp[i:i + c_avg_per_n_steps].mean() for i in\n",
    "                        range(0, curr_sem_data.shape[1] - c_avg_per_n_steps + 1, c_avg_per_n_steps)]\n",
    "\n",
    "            stats_dict[game_type][agent_type + \"_m\"] = np.array(avg_ma).reshape(\n",
    "                int(curr_avg_data.shape[1] / c_avg_per_n_steps))\n",
    "            stats_dict[game_type][agent_type + \"_se\"] = np.array(avg_se).reshape(\n",
    "                int(curr_sem_data.shape[1] / c_avg_per_n_steps))\n",
    "\n",
    "    return stats_dict\n",
    "\n",
    "\n",
    "# perturbated=True: Plots the stress tests\n",
    "# only_first_100=True: Plots only the first hundred\n",
    "# last_100=True: Plots only the last hundred\n",
    "def plotter(stats, game_type, agent_types, avg_per_n_steps, perturbated=False, only_first_100=False, last_100=False, save_data=False):\n",
    "    st = stats[game_type]\n",
    "    \n",
    "    for i, a in enumerate(agent_types):\n",
    "        \n",
    "        ## Saving data files for t-tests and BF's\n",
    "        if perturbated:  \n",
    "            if i == 0:\n",
    "                after_perturbation = {}          \n",
    "            if a not in ['human', 'data_sf', 'human_extended']:\n",
    "                after_perturbation[a + \"_all\"] = list(np.asarray(st[a].T.explode([i for i in range(0, st[a].shape[0])]).mean(axis=1).T))\n",
    "                after_perturbation[a + \"_averaged\"] = list(np.average(np.asarray(st[a].T.explode([i for i in range(0, st[a].shape[0])]).mean(axis=1)).reshape(-1, 40), axis=1))\n",
    "            else:\n",
    "                after_perturbation[\"human\"] = list(np.asarray(st[a].T.explode([i for i in range(0, st[a].shape[0])]).mean(axis=1).T))\n",
    "\n",
    "        else:\n",
    "            if i == 0:\n",
    "                jdata = {}\n",
    "\n",
    "            if a in ['human', 'data_sf', 'human_extended']:\n",
    "                jdata[a] = st[a].T.values.tolist()\n",
    "                jdata[a + '_avg'] = np.mean(st[a + '_m'])\n",
    "            else:\n",
    "                jdata[a + '_first_150'] = np.asarray([t[:150] for t in (\n",
    "                            list(st[a].iloc[:, 0:].values.T)[0] + list(st[a].iloc[:, 0:].values.T)[1])]).T.tolist()\n",
    "                jdata[a + '_first_150_avg'] = np.mean(st[a + '_m'][:150])\n",
    "                jdata[a + '_last_100'] = np.asarray([t[:100] for t in list(st[a].iloc[:, -1:].values.T)[0]]).T.tolist()\n",
    "                jdata[a + '_last_100_avg'] = np.mean(st[a + '_m'][-100:])\n",
    "\n",
    "                if game_type == \"logic_game\" and avg_per_n_steps == 1:\n",
    "                    jdata[a + '_all'] = list(st[a + '_m'])\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    # Hide the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "    axes = plt.gca()\n",
    "\n",
    "    ##### Cosmetic #####\n",
    "    cosmetic_change(game_type, ax, axes, last_100, agent_types, only_first_100, perturbated, avg_per_n_steps)\n",
    "\n",
    "    for j, agent_type in enumerate(agent_types):  # Plot each line\n",
    "        if agent_type not in ['human', 'data_sf', 'human_extended']:  # Algorithms\n",
    "\n",
    "            xs = [int(i * avg_per_n_steps) for i in range(0, len(st[agent_type + \"_m\"]))]\n",
    "            temp_xs = []\n",
    "            if last_100:\n",
    "                for a in xs:\n",
    "                    if a < 100:\n",
    "                        temp_xs.append(a)\n",
    "                xs = temp_xs\n",
    "                r_l = ax.plot(xs, st[agent_type + \"_m\"][-int(100 / avg_per_n_steps):], color=colors[agent_type],\n",
    "                              linewidth=4 if agent_type == \"self_class\" else 1,\n",
    "                              label=label_dict[agent_type])\n",
    "                ax.fill_between(xs, st[agent_type + \"_m\"][-int(100 / avg_per_n_steps):] - st[agent_type + \"_se\"][\n",
    "                                                                                     -int(100 / avg_per_n_steps):],\n",
    "                                st[agent_type + \"_m\"][-int(100 / avg_per_n_steps):] + st[agent_type + \"_se\"][\n",
    "                                                                                 -int(100 / avg_per_n_steps):],\n",
    "                                alpha=0.08, color=colors[agent_type])\n",
    "            else:\n",
    "                if \"self_class\" in agent_type:\n",
    "                    r_l = ax.plot(xs, st[agent_type + \"_m\"], color=colors[agent_type],\n",
    "                                  linewidth=4 if only_first_100 or last_100 else 2,\n",
    "                                  label=label_dict[agent_type])\n",
    "                else:\n",
    "                    r_l = ax.plot(xs, st[agent_type + \"_m\"], color=colors[agent_type], linewidth=1,\n",
    "                                  label=label_dict[agent_type])\n",
    "                ax.fill_between(xs, st[agent_type + \"_m\"] - st[agent_type + \"_se\"],\n",
    "                                st[agent_type + \"_m\"] + st[agent_type + \"_se\"], alpha=0.08,\n",
    "                                color=colors[agent_type])\n",
    "        else:  # Human\n",
    "            if agent_type in ['human', 'human_extended'] and perturbated and avg_per_n_steps != 1:\n",
    "                c_avg_per_n_steps = 1\n",
    "            else:\n",
    "                c_avg_per_n_steps = avg_per_n_steps\n",
    "            xs = [int(i * c_avg_per_n_steps) for i in range(0, len(st[\"{}_m\".format(agent_type)]))]\n",
    "            if last_100:\n",
    "                hum_l = ax.plot(xs, st['{}_m'.format(agent_type)], color=colors[agent_type], linewidth=4,\n",
    "                                label=label_dict[agent_type], linestyle='dashed', zorder=9999)\n",
    "            else:\n",
    "                hum_l = ax.plot(xs, st['{}_m'.format(agent_type)], color=colors[agent_type], linewidth=4,\n",
    "                                label=label_dict[agent_type], zorder=9999)\n",
    "            x = [int(i * c_avg_per_n_steps) for i in range(0, len(st[\"{}_m\".format(agent_type)]))]\n",
    "            ax.fill_between(x, st['{}_m'.format(agent_type)] - st['{}_se'.format(agent_type)],\n",
    "                            st['{}_m'.format(agent_type)] + st['{}_se'.format(agent_type)],\n",
    "                            alpha=0.08, color=colors[agent_type])\n",
    "    plt.tight_layout()\n",
    "    if perturbated:\n",
    "        if \"human_extended\" in agent_types:\n",
    "            if game_type == \"change_agent_game\":\n",
    "                if only_first_100:\n",
    "                    plt.axvline(x=20, color=\"#ffff03\", alpha=0.2, linewidth=15)\n",
    "                else:\n",
    "                    plt.axvline(x=2000, color=\"#ffff03\", alpha=0.2, linewidth=15)\n",
    "            else:\n",
    "                plt.axvline(x=100, color=\"#ffff03\", alpha=0.2, linewidth=15) if only_first_100 else plt.axvline(x=2000,\n",
    "                                                                                                                color=\"#ffff03\",\n",
    "                                                                                                                alpha=0.2,\n",
    "                                                                                                                linewidth=15)\n",
    "        else:\n",
    "            plt.axvline(x=2000, color=\"#ffff03\", alpha=0.2, linewidth=15)\n",
    "\n",
    "    #leg = plt.legend(bbox_to_anchor=(1, 1), loc='upper left', title_fontsize=25)\n",
    "    #plt.rc('legend', fontsize=25)\n",
    "\n",
    "    #for legobj in leg.legendHandles:\n",
    "    #    legobj.set_linewidth(6.0)\n",
    "\n",
    "    # For plotting bayes lines\n",
    "    bfs = {}\n",
    "\n",
    "    try:\n",
    "        if only_first_100:\n",
    "            f = open(\"../stats/{}_bfs.json\".format(game_type))\n",
    "            bfs[game_type] = json.load(f)[game_type][\"perturbated\" if perturbated else \"normal\"]\n",
    "            bf = bfs[game_type]\n",
    "\n",
    "            for x, s in enumerate(bf):\n",
    "                if s == 1:\n",
    "                    if game_type == \"logic_game\":\n",
    "                        ax.hlines(xmin=max(0, x - 0.5), xmax=x + 0.5, y=17, linewidth=12, color=\"#0373fc\")\n",
    "                    elif game_type == \"contingency_game\":\n",
    "                        ax.hlines(xmin=max(0, x - 0.5), xmax=x + 0.5, y=45, linewidth=12, color=\"#0373fc\")\n",
    "                    elif game_type in [\"change_agent_game\", \"change_agent_game_harder\"]:\n",
    "                        if perturbated:\n",
    "                            ax.hlines(xmin=max(0, x - 0.5), xmax=x + 0.5, y=300, linewidth=12, color=\"#0373fc\")\n",
    "                        else:\n",
    "                            ax.hlines(xmin=max(0, x - 0.5), xmax=x + 0.5, y=150, linewidth=12, color=\"#0373fc\")\n",
    "                    elif game_type == \"contingency_game_shuffled_1\":\n",
    "                        ax.hlines(xmin=max(0, x - 0.5), xmax=x + 0.5, y=45, linewidth=12, color=\"#0373fc\")\n",
    "    except:\n",
    "        print(\"No bf\")\n",
    "\n",
    "    path = './plots/{}/'.format(game_type)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # Human vs. Self\n",
    "    hs = ''\n",
    "    if only_first_100 and ((\"self_class\" in agent_types) and (\"human\" in agent_types)):\n",
    "        hs = '_human_vs_self'\n",
    "\n",
    "\n",
    "    if not save_data:\n",
    "        plt.show()\n",
    "        fig.savefig(\n",
    "            path + 'effiency_curves_' + game_type + '{}{}{}{}{}.pdf'.format('_' + str(avg_per_n_steps),\n",
    "                                                                            '_first_100' if only_first_100 else '',\n",
    "                                                                            '_last_100' if last_100 else '',\n",
    "                                                                            '_perturbated' if perturbated else '',\n",
    "                                                                            hs),\n",
    "            format='pdf',\n",
    "            bbox_inches=\"tight\")\n",
    "\n",
    "    if save_data and perturbated:\n",
    "        try:\n",
    "            with open('../stats/data_{}_after_perturbation.json'.format(game_type), 'w+') as fp:  # Save data files\n",
    "                json.dump(after_perturbation, fp, indent=4)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    if save_data and not perturbated:\n",
    "        try:\n",
    "            with open('../stats/data_{}.json'.format(game_type), 'w+') as fp:  # Save data files\n",
    "                print(\"*** Saving: \", jdata)\n",
    "                json.dump(jdata, fp, indent=4)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "# Append stats of two data (normal + include_perturbation)\n",
    "def append_stats(dict_normal, dict_ext, game_types, game_types_ext):\n",
    "    appended_data = {}\n",
    "    for i, game in enumerate(game_types):\n",
    "        appended_data[game] = {}\n",
    "        for key, value in dict_normal[game].items():\n",
    "            data_normal = dict_normal[game][key]\n",
    "            data_ext = dict_ext[game_types_ext[i]][key]\n",
    "            appended_data[game][key] = np.concatenate((data_normal, data_ext))\n",
    "\n",
    "    return appended_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### CONTINGENCY GAME #########################\n",
    "\n",
    "game = \"contingency_game\"  # \"logic_game\", \"contingency_game_shuffled_1\", \"change_agent_game\",\n",
    "\n",
    "# For saving data\n",
    "agents = [\"human\", \"human_extended\", \"data_sf\", \"self_classshort\", \"self_class\", \"trpo_training\", \"acer_training\", \"ppo2_training\", \"dqn_training\", \"a2c_training\", \"option_critic\"]\n",
    "stats = get_performance(game, agents, avg_per_n_steps=20, single_seed=False,\n",
    "                            include_perturbation=False)\n",
    "plotter(stats, game, agents, avg_per_n_steps=20, perturbated=False, save_data=True)\n",
    "\n",
    "agent_types = [\"self_class\", \"random\", \"human\", \"a2c_training\", \"trpo_training\", \"acer_training\", \"ppo2_training\", \"dqn_training\", \"option_critic\"]\n",
    "\n",
    "avg_per_n_steps = 20\n",
    "    \n",
    "# *-*-*-*-* 2000 Levels (Main Plot) *-*-*-*-* #\n",
    "stats_dict = get_performance(game, agent_types, avg_per_n_steps, single_seed=False, include_perturbation=False)\n",
    "plotter(stats_dict, game, agent_types, avg_per_n_steps, perturbated=False)\n",
    "\n",
    "# *-*-*-*-* Last Hundred *-*-*-*-* #\n",
    "plotter(stats_dict, game, [\"self_class\", \"a2c_training\", \"trpo_training\", \"acer_training\", \"ppo2_training\", \"dqn_training\", \"option_critic\"], avg_per_n_steps, last_100=True)\n",
    "\n",
    "# *-*-*-*-* First Hundred *-*-*-*-* #\n",
    "agents_fs = [\"human\", \"self_class\"]\n",
    "plotter(get_performance(game, agents_fs, 1, single_seed=False), game, agents_fs, 1, only_first_100=True)\n",
    "        \n",
    "# *-*-*-*-* Perturbations *-*-*-*-* #\n",
    "if game not in [\"logic_game\", \"contingency_game_shuffled_1\"]:  # These games do not have perturbations\n",
    "    agents_stress = [\"self_class\", \"trpo_training\", \"acer_training\", \"ppo2_training\", \"dqn_training\", \"option_critic\", \"a2c_training\"]\n",
    "    stress_stats = get_performance(game, agents_stress, avg_per_n_steps, single_seed=False, include_perturbation=True)\n",
    "    plotter(stress_stats, game, agents_stress, avg_per_n_steps, perturbated=True)\n",
    "\n",
    "    agents_stress = [\"self_classshort\", \"human_extended\"]\n",
    "    stress_stats = get_performance(game, agents_stress, avg_per_n_steps=1, single_seed=False,\n",
    "                                include_perturbation=True)\n",
    "    plotter(stress_stats, game, agents_stress, avg_per_n_steps=1, perturbated=True, only_first_100=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "######################### SWITCHING EMBODIMENTS GAME #########################\n",
    "\n",
    "game = \"change_agent_game\"  # \"logic_game\", \"contingency_game_shuffled_1\", \"change_agent_game\",\n",
    "\n",
    "# For saving data\n",
    "agents = [\"human\", \"human_extended\", \"self_class\", \"trpo_training\", \"acer_training\", \"ppo2_training\", \"dqn_training\", \"a2c_training\", \"keep_close\", \"option_critic\"]\n",
    "stats = get_performance(game, agents, avg_per_n_steps=20, single_seed=False,\n",
    "                            include_perturbation=False)\n",
    "plotter(stats, game, agents, avg_per_n_steps=20, perturbated=False, save_data=True)\n",
    "\n",
    "agent_types = [\"self_class\", \"random\", \"human\", \"a2c_training\", \"trpo_training\", \"acer_training\", \"ppo2_training\", \"dqn_training\", \"option_critic\", \"keep_close\"]  # 'random'\n",
    "\n",
    "avg_per_n_steps = 20\n",
    "    \n",
    "# *-*-*-*-* 2000 Levels (Main Plot) *-*-*-*-* #\n",
    "stats_dict = get_performance(game, agent_types, avg_per_n_steps, single_seed=False, include_perturbation=False)\n",
    "plotter(stats_dict, game, agent_types, avg_per_n_steps, perturbated=False)\n",
    "\n",
    "# *-*-*-*-* Last Hundred *-*-*-*-* #\n",
    "plotter(stats_dict, game, [\"self_class\", \"a2c_training\", \"trpo_training\", \"acer_training\", \"ppo2_training\", \"dqn_training\", \"option_critic\", \n",
    "                            \"keep_close\"], avg_per_n_steps, last_100=True)\n",
    "\n",
    "# *-*-*-*-* First Hundred *-*-*-*-* #\n",
    "agents_fs = [\"human\", \"self_class\"]\n",
    "plotter(get_performance(game, agents_fs, 1, single_seed=False), game, agents_fs, 1, only_first_100=True)\n",
    "        \n",
    "# *-*-*-*-* Perturbations *-*-*-*-* #\n",
    "if game not in [\"logic_game\", \"contingency_game_shuffled_1\"]:  # These games do not have perturbations\n",
    "    agents_stress = [\"keep_close\", \"self_class\", \"trpo_training\", \"acer_training\", \"ppo2_training\", \"dqn_training\", \"option_critic\", \"a2c_training\"]\n",
    "    stress_stats = get_performance(game, agents_stress, avg_per_n_steps, single_seed=False, include_perturbation=True)\n",
    "    plotter(stress_stats, game, agents_stress, avg_per_n_steps, perturbated=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################  HARDER PERTURBATION TASK IN SWITCHING EMBODIMENTS GAME  #########################################\n",
    "\n",
    "# Save data file for stats\n",
    "agents_stress = [\"human_extended\", \"self_classshort\", \"self_class\", \"trpo_training\", \"acer_training\", \"ppo2_training\", \"dqn_training\", \"a2c_training\", \"keep_close\"]\n",
    "stress_stats = get_performance('change_agent_game_harder', agents_stress, avg_per_n_steps=20, single_seed=False,\n",
    "                            include_perturbation=True)\n",
    "plotter(stress_stats, 'change_agent_game_harder', agents_stress, avg_per_n_steps=20, perturbated=False, save_data=True)\n",
    "\n",
    "# Harder Stress Test for Switching Embodiments Game:\n",
    "agents_stress = [\"self_class\", \"trpo_training\", \"acer_training\", \"ppo2_training\", \"dqn_training\", \"a2c_training\", \"keep_close\"]\n",
    "stress_stats = get_performance('change_agent_game_harder', agents_stress, avg_per_n_steps=20, single_seed=False,\n",
    "                            include_perturbation=True)\n",
    "plotter(stress_stats, 'change_agent_game_harder', agents_stress, avg_per_n_steps=20, perturbated=True, save_data=False)\n",
    "\n",
    "# Harder Stress Test for human participants\n",
    "agents_stress = [\"self_classshort\", \"human_extended\"]\n",
    "stress_stats = get_performance('change_agent_game_harder', agents_stress, avg_per_n_steps=1, single_seed=False,\n",
    "                               include_perturbation=True)\n",
    "plotter(stress_stats, 'change_agent_game_harder', agents_stress, avg_per_n_steps=1, perturbated=True, only_first_100=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----- Plot the number of steps the player takes before any agent moves from its starting location\n",
    "\n",
    "# Plot no-movement action count of agent for each level\n",
    "def plot_nm_ac(game_types, agent_types, avg_per_n_steps=1, only_first_100=False):\n",
    "    for i, game_type in enumerate(game_types):\n",
    "        nm_ac = get_all_nm_ac(agent_types, game_type, avg_per_n_steps)\n",
    "\n",
    "        if avg_per_n_steps == 1: # Save human nm_ac for each level        \n",
    "            pd.DataFrame.from_dict(nm_ac, orient='index').T.to_csv('../stats/self_orienting_logic_game.csv')\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "        ax.xaxis.label.set_size(25)\n",
    "        ax.yaxis.label.set_size(25)\n",
    "\n",
    "        if only_first_100:\n",
    "            ax.set_xlim([0, 100])\n",
    "\n",
    "        ax.set_xlabel(xlabel=\"Levels Played\", labelpad=21)\n",
    "\n",
    "        ax.set_ylabel(ylabel=\"No. Steps Until Self Orienting\\nAveraged Every {} Levels\".format(avg_per_n_steps),\n",
    "                      labelpad=21)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=30)\n",
    "\n",
    "        for j, agent in enumerate(agent_types):\n",
    "            xs = [int(i * avg_per_n_steps) for i in range(0, len(nm_ac[agent + \"_m\"]))]\n",
    "            line_width = 3 if agent == 'human' else 1\n",
    "            ax.plot(xs, nm_ac[agent + \"_m\"], color=colors[agent], linewidth=line_width, label=label_dict[agent])\n",
    "            upper_curve = [nm_ac[agent + '_m'][i] + nm_ac[agent + '_se'][i] for i in\n",
    "                           range(len(nm_ac[agent + '_m']))]\n",
    "            lower_curve = [nm_ac[agent + '_m'][i] - nm_ac[agent + '_se'][i] for i in\n",
    "                           range(len(nm_ac[agent + '_m']))]\n",
    "            x = [int(i * avg_per_n_steps) for i in range(0, len(nm_ac[agent + \"_m\"]))]\n",
    "            ax.fill_between(x, lower_curve, upper_curve, alpha=0.05, color=colors[agent])\n",
    "\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        #plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize='xx-large')\n",
    "\n",
    "        fs = 50 if 'contingency_game' in game_type else 25\n",
    "        fs = 100 if 'contingency_game_shuffled' in game_type else fs\n",
    "\n",
    "        #leg = plt.legend(bbox_to_anchor=(1, 1), loc='upper left', title_fontsize=fs)\n",
    "        #plt.rc('legend', fontsize=fs)\n",
    "\n",
    "        #for legobj in leg.legendHandles:\n",
    "        #    legobj.set_linewidth(6.0)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        path = './plots/{}/{}/'.format(game_type, 'curves')\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        fig.savefig(path + 'no_movement_action_count_{}{}.pdf'.format(game_type, avg_per_n_steps), format='pdf')\n",
    "\n",
    "\n",
    "## Get no-movement action count of agent for each level and each game as a dictionary\n",
    "def get_all_nm_ac(agent_types, game_type, avg_per_n_steps):\n",
    "    # Check if saved data exists\n",
    "    fpath = './plotting_data/nm_ac_' + game_type + \"_batchSize=\" + str(avg_per_n_steps) + \".pickle\"\n",
    "    if exists(fpath):\n",
    "        return pickle.load(open(fpath, 'rb'))\n",
    "\n",
    "    stats = {}\n",
    "    for agent in agent_types:\n",
    "        stats[agent + \"_m\"], stats[agent + \"_se\"] = get_nm_ac(agent, game_type, avg_per_n_steps)\n",
    "\n",
    "    # Save data\n",
    "    with open(fpath, 'wb') as f:\n",
    "        pickle.dump(stats, f)\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "## Get no-movement action count of agent for each level\n",
    "def get_nm_ac(agent_type, game_type, avg_per_n_steps):\n",
    "    files = glob.glob(\"../data/\" + game_type + \"/\" + agent_type + \"/*/*.json\")\n",
    "\n",
    "    if len(files) == 0:\n",
    "        files = glob.glob(\"../data/\" + game_type + \"/\" + agent_type + \"/*.json\")\n",
    "\n",
    "    all_seeds = []\n",
    "    curr_seed = []\n",
    "    seed = 0\n",
    "    curr_file_count = 0\n",
    "    file_amt = len(files)\n",
    "\n",
    "    if agent_type not in [\"human\", \"random\"]:\n",
    "        files = [x for x in files if int(x.split(\"/\")[-1][6:-5]) <= 1900]\n",
    "\n",
    "    sorted_files = sorted(files, key=os.path.getmtime if agent_type == 'human' else get_seed_num_and_iter)\n",
    "    for i, file in enumerate(sorted_files):\n",
    "        print(\"Getting... \", file)\n",
    "        data = json.load(open(file))\n",
    "        self_locs = data.get(\"data\")[\"self_locs\"]\n",
    "\n",
    "        level_amt = 100\n",
    "        action_count = [1] * level_amt\n",
    "\n",
    "        # In each 100 levels:\n",
    "        for level in range(level_amt):\n",
    "            if len(self_locs[level]) == 0:\n",
    "                continue\n",
    "            action_amt = len(self_locs[level][0])\n",
    "            for i in range(action_amt):\n",
    "                if i == level_amt:\n",
    "                    break\n",
    "\n",
    "                x = self_locs[level][0][i]\n",
    "                y = self_locs[level][1][i]\n",
    "                x1 = self_locs[level][0][i + 1]\n",
    "                y1 = self_locs[level][1][i + 1]\n",
    "\n",
    "                if x == x1 and y == y1:  # Still in the same position\n",
    "                    action_count[level] = action_count[level] + 1\n",
    "                else:  # Position have changed\n",
    "                    break\n",
    "\n",
    "        curr_file_count += 1\n",
    "        curr_seed.append(action_count)\n",
    "\n",
    "        if agent_type == 'human' and (curr_file_count == file_amt or file_amt == 1):\n",
    "            all_seeds = curr_seed\n",
    "            break\n",
    "\n",
    "        if agent_type != 'human' and curr_file_count == 20:\n",
    "            all_seeds.append(curr_seed)\n",
    "            curr_seed = []\n",
    "            curr_file_count = 0\n",
    "            seed += 1\n",
    "\n",
    "    all_seeds = pd.DataFrame(all_seeds)\n",
    "\n",
    "    seed_average = []\n",
    "    seed_sem = []\n",
    "    for column in all_seeds:\n",
    "        seed_average.append(np.mean(list(all_seeds[column]), axis=0))\n",
    "        seed_sem.append((pd.DataFrame(list(all_seeds[column]))).sem(axis=0))\n",
    "\n",
    "    curr_avg_data = pd.DataFrame(seed_average).T\n",
    "    curr_sem_data = pd.DataFrame(seed_sem).T\n",
    "\n",
    "    if agent_type != 'human':\n",
    "        seed_mean = np.array(\n",
    "            [curr_avg_data[column].groupby(curr_avg_data.index // avg_per_n_steps).mean() for column in\n",
    "             curr_avg_data]).reshape(\n",
    "            int(curr_avg_data.shape[1] * 100 * 1 / avg_per_n_steps))\n",
    "        s_sem = np.array(\n",
    "            [curr_sem_data[column].groupby(curr_sem_data.index // avg_per_n_steps).mean() for column in\n",
    "             curr_sem_data]).reshape(\n",
    "            int(curr_sem_data.shape[1] * 100 * 1 / avg_per_n_steps))\n",
    "    else:\n",
    "        temp = np.asarray(curr_avg_data).T\n",
    "        avg_ma = [temp[i:i + avg_per_n_steps].mean() for i in range(0, curr_avg_data.shape[1] - avg_per_n_steps + 1, avg_per_n_steps)]\n",
    "\n",
    "        temp = np.asarray(curr_sem_data).T\n",
    "        avg_se = [temp[i:i + avg_per_n_steps].mean() for i in range(0, curr_sem_data.shape[1] - avg_per_n_steps + 1, avg_per_n_steps)]\n",
    "\n",
    "        seed_mean = np.array(avg_ma).reshape(int(curr_avg_data.shape[1] / avg_per_n_steps))\n",
    "        s_sem = np.array(avg_se).reshape(int(curr_sem_data.shape[1] / avg_per_n_steps))\n",
    "\n",
    "    return seed_mean, s_sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Action Counts Without Movement -- Only For Logic Game\n",
    "\n",
    "agent_types = [\"human\", \"self_class\", \"random\", \"a2c_training\", \"trpo_training\", \"acer_training\", \"ppo2_training\",\n",
    "               \"dqn_training\", \"option_critic\"]\n",
    "game_types = [\"logic_game\"]\n",
    "plot_nm_ac(game_types, agent_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ----- Plot average distance from the goal for each level\n",
    "def plot_avg_distance(game_types, agent_types, avg_per_n_steps=50, level=1999):\n",
    "    for i, game_type in enumerate(game_types):\n",
    "        avg_distance = get_all_avg_distance(agent_types, game_type, avg_per_n_steps, level)\n",
    "        xls = [150]\n",
    "        for xl in xls:\n",
    "            fig, ax = plt.subplots(figsize=(20, 10))\n",
    "            ax.set_xlim([0, xl])\n",
    "            ax.xaxis.label.set_size(25)\n",
    "            ax.yaxis.label.set_size(25)\n",
    "\n",
    "            #ax.set_xlabel(xlabel=\"Step\", labelpad=21)\n",
    "            #ax.set_ylabel(ylabel=\"Average Distance to Goal\", labelpad=21)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=17)\n",
    "            ax.xaxis.set_tick_params(labelsize=25)\n",
    "            ax.yaxis.set_tick_params(labelsize=25)\n",
    "            #ax.set_title(game_titles[game_type], fontweight='bold', fontsize=25)\n",
    "\n",
    "            for j, agent in enumerate(agent_types):\n",
    "                xs = [int(i * avg_per_n_steps) for i in range(0, len(avg_distance[agent + \"_m\"]))]\n",
    "                line_width = 4 if agent == 'human' or agent == 'self_class' else 1\n",
    "                ax.plot(xs, avg_distance[agent + \"_m\"], color=colors[agent], linewidth=line_width,\n",
    "                        label=label_dict[agent])\n",
    "                upper_curve = [avg_distance[agent + '_m'][i] + avg_distance[agent + '_se'][i] for i in\n",
    "                               range(len(avg_distance[agent + '_m']))]\n",
    "                lower_curve = [avg_distance[agent + '_m'][i] - avg_distance[agent + '_se'][i] for i in\n",
    "                               range(len(avg_distance[agent + '_m']))]\n",
    "                x = [int(i * avg_per_n_steps) for i in range(0, len(avg_distance[agent + \"_m\"]))]\n",
    "                ax.fill_between(x, lower_curve, upper_curve, alpha=0.08, color=colors[agent])\n",
    "\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            ax.spines['top'].set_visible(False)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            path = './plots/{}/{}/'.format(game_type, 'curves')\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "\n",
    "            fig.savefig(path + '{}_distance_{}{}{}.pdf'.format(xl, game_type, avg_per_n_steps, level), format='pdf')\n",
    "\n",
    "\n",
    "def get_all_avg_distance(agent_types, game_type, avg_per_n_steps, level=0):\n",
    "    # Check if saved data exists\n",
    "    fpath = './plotting_data/dist_' + game_type + \"_batchSize=\" + str(avg_per_n_steps) + \"level={}\".format(\n",
    "        str(level)) + \".pickle\"\n",
    "    if exists(fpath):\n",
    "        return pickle.load(open(fpath, 'rb'))\n",
    "\n",
    "    stats = {}\n",
    "    for agent in agent_types:\n",
    "        print(agent + \"_m\")\n",
    "        stats[agent + \"_m\"], stats[agent + \"_se\"] = get_avg_distance(agent, game_type, avg_per_n_steps, level)\n",
    "\n",
    "    # Save data\n",
    "    with open(fpath, 'wb') as f:\n",
    "        pickle.dump(stats, f)\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "# Ignore avg_per_n_steps here, as it does not mean anything\n",
    "def get_avg_distance(agent_type, game_type, avg_per_n_steps, level=0):\n",
    "    if avg_per_n_steps != 1:\n",
    "        print(\"Batch size should be 1\")\n",
    "        return\n",
    "    files = glob.glob(\"../data/\" + game_type + \"/\" + agent_type + \"/*/*.json\")\n",
    "\n",
    "    if len(files) == 0:\n",
    "        files = glob.glob(\"../data/\" + game_type + \"/\" + agent_type + \"/*.json\")\n",
    "\n",
    "    all_seeds = []\n",
    "    curr_file_count = 0\n",
    "\n",
    "    if agent_type not in [\"human\", \"random\"]:\n",
    "        files = [x for x in files if int(x.split(\"/\")[-1][6:-5]) <= 1900]\n",
    "\n",
    "    sorted_files = sorted(files, key=os.path.getmtime if agent_type == 'human' else get_seed_num_and_iter)\n",
    "\n",
    "    if agent_type != 'human':\n",
    "        if level == 1:\n",
    "            sorted_files = [sorted_files[j] for j in range(0, len(files), 20)]\n",
    "        elif level == 1999:  # Get the files that only contain the last level\n",
    "            sf = []\n",
    "            for j in range(0, len(files), 20):\n",
    "                sf.append(sorted_files[j - 1])\n",
    "            sorted_files = sf\n",
    "\n",
    "    file_amt = len(sorted_files)\n",
    "    level = level % 100\n",
    "\n",
    "    # For each seed/subject:\n",
    "    for i, file in enumerate(sorted_files):\n",
    "        print(\"Getting... \", file)\n",
    "        data = json.load(open(file))\n",
    "        self_locs = data.get(\"data\")[\"self_locs\"]\n",
    "\n",
    "        #level_amt = 100\n",
    "        action_amt = len(self_locs[level][0])\n",
    "\n",
    "        # Store distance to goal at every action for a particular seed\n",
    "        distances = [0 for y in range(action_amt)]\n",
    "\n",
    "        if len(self_locs[level]) == 0:\n",
    "            continue\n",
    "\n",
    "        # In each action:\n",
    "        for action_index in range(action_amt):\n",
    "            x = self_locs[level][0][action_index]\n",
    "            y = self_locs[level][1][action_index]\n",
    "\n",
    "            if x == 0:\n",
    "                print(\"?\")\n",
    "\n",
    "            if game_type == \"logic_game\":\n",
    "                distances[action_index] = abs(x - 4) + abs(y - 4)\n",
    "\n",
    "                if (abs(x - 4) + abs(y - 4)) > 6:\n",
    "                    print(\"how?\")\n",
    "            else:\n",
    "                distances[action_index] = abs(x - 10) + abs(y - 10)\n",
    "\n",
    "        curr_file_count += 1\n",
    "        all_seeds.append(distances)\n",
    "\n",
    "    all_seeds = pd.DataFrame(all_seeds).fillna(0)\n",
    "\n",
    "    if agent_type == 'human':\n",
    "        if game_type == \"logic_game\":\n",
    "            all_seeds.insert(loc=0, value=pd.DataFrame([6 for i in range(file_amt)]),\n",
    "                            column=-1)  # Set starting distance (8)\n",
    "        else:\n",
    "            all_seeds.insert(loc=0, value=pd.DataFrame([8 for i in range(file_amt)]),\n",
    "                            column=-1)  # Set starting distance (8)\n",
    "\n",
    "    seed_average = []\n",
    "    seed_sem = []\n",
    "    for column in all_seeds:\n",
    "        seed_average.append(np.mean(list(all_seeds[column]), axis=0))\n",
    "        seed_sem.append((pd.DataFrame(list(all_seeds[column]))).sem(axis=0))\n",
    "\n",
    "    curr_avg_data = pd.DataFrame(seed_average).T\n",
    "    curr_sem_data = pd.DataFrame(seed_sem).T\n",
    "\n",
    "    if agent_type != 'human':  # AI\n",
    "        seed_mean = np.array(\n",
    "            [curr_avg_data[column].groupby(curr_avg_data.index // avg_per_n_steps).mean() for column in\n",
    "             curr_avg_data]).reshape(\n",
    "            int(curr_avg_data.shape[1] * 1 / avg_per_n_steps))\n",
    "        s_sem = np.array(\n",
    "            [curr_sem_data[column].groupby(curr_sem_data.index // avg_per_n_steps).mean() for column in\n",
    "             curr_sem_data]).reshape(\n",
    "            int(curr_sem_data.shape[1] * 1 / avg_per_n_steps))\n",
    "    else:\n",
    "        temp = np.asarray(curr_avg_data).T\n",
    "        avg_ma = [temp[i:i + avg_per_n_steps].mean() for i in range(0, curr_avg_data.shape[1] - avg_per_n_steps + 1, avg_per_n_steps)]\n",
    "\n",
    "        temp = np.asarray(curr_sem_data).T\n",
    "        avg_se = [temp[i:i + avg_per_n_steps].mean() for i in range(0, curr_sem_data.shape[1] - avg_per_n_steps + 1, avg_per_n_steps)]\n",
    "\n",
    "        seed_mean = np.array(avg_ma).reshape(int(curr_avg_data.shape[1] / avg_per_n_steps))\n",
    "        s_sem = np.array(avg_se).reshape(int(curr_sem_data.shape[1] / avg_per_n_steps))\n",
    "\n",
    "    return seed_mean, s_sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agent_types = [\"human\", \"self_class\", \"random\", \"a2c_training\", \"trpo_training\", \"acer_training\", \"ppo2_training\",\n",
    "               \"dqn_training\", \"option_critic\", \"keep_close\"]\n",
    "game_types = [\n",
    "    \"change_agent_game\", ]  #\"contingency_game_shuffled_1\"] #, \"contingency_game\", \"change_agent_game\", \"contingency_game_shuffled_100\", \"contingency_game_shuffled_200\"\n",
    "plot_avg_distance(game_types, agent_types, avg_per_n_steps=1, level=1)\n",
    "plot_avg_distance(game_types, agent_types, avg_per_n_steps=1, level=1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Plot self finding steps in contingency game for each level #####\n",
    "\n",
    "def plot_self_finding(game_type):\n",
    "    means, ses = get_self_finding_steps(game_type)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "    ax.xaxis.label.set_size(25)\n",
    "    ax.yaxis.label.set_size(25)\n",
    "\n",
    "    ax.set_xlabel(xlabel=\"Levels Played\", labelpad=21)\n",
    "\n",
    "    ax.set_ylabel(ylabel=\"No. Steps Until Self Orienting\",\n",
    "                  labelpad=21)\n",
    "    ax.set_ylim([0, 10])\n",
    "\n",
    "    if game_type == 'contingency_game_shuffled_1':\n",
    "        ax.set_ylim([0, 50])\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=30)\n",
    "\n",
    "    xs = [int(i) for i in range(0, len(means))]\n",
    "    line_width = 3\n",
    "    ax.plot(xs, means, color=colors['human'], linewidth=3, label=label_dict['human'])\n",
    "    upper_curve = [means[i] + ses[i] for i in\n",
    "                   range(len(means))]\n",
    "    lower_curve = [means[i] - ses[i] for i in\n",
    "                   range(len(means))]\n",
    "\n",
    "    ax.fill_between(xs, lower_curve, upper_curve, alpha=0.05, color=colors['human'])\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    path = './plots/{}/{}/'.format(game_type, 'curves')\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    fig.savefig(path + 'self_finding_' + game_type + '.pdf', format='pdf')\n",
    "\n",
    "\n",
    "## Get no-movement action count of agent for each level\n",
    "def get_self_finding_steps(game_type):\n",
    "    files = glob.glob(\"../data/\" + game_type + \"/data_sf/*.json\")\n",
    "\n",
    "    file_amt = len(files)\n",
    "    level_means = []\n",
    "    level_ses = []\n",
    "\n",
    "    for level in range(0, 100):  # Data for each level\n",
    "        curr_lvl = []\n",
    "        for i, file in enumerate(files):  # Get the data for each participant in that level\n",
    "            data = json.load(open(file))\n",
    "            selected_agents = data.get(\"selectedAgents\")\n",
    "\n",
    "            # Find the current level\n",
    "            c_level = [d for d in selected_agents if d['level'] == level and d['real_self'] == d['clicked_self']]\n",
    "            if len(c_level) == 1:\n",
    "                #if level > 5 and c_level[0]['step'] > 20:\n",
    "                #    print(\"Level: {} -- Step: {} -- File: {}\".format(str(level), str(c_level[0]['step']), file))\n",
    "                curr_lvl.append(c_level[0]['step'])\n",
    "\n",
    "        level_means.append(statistics.mean(curr_lvl))\n",
    "        level_ses.append(sem(curr_lvl))\n",
    "\n",
    "    df = pd.DataFrame({'level_means': level_means})\n",
    "    df.to_csv('../stats/self_orienting_{}.csv'.format(game_type))\n",
    "\n",
    "    return level_means, level_ses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_self_finding(\"contingency_game\")\n",
    "#plot_self_finding(\"contingency_game_shuffled_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "236e899f380a2c5c83c683f080eed40086d3970855ebd76444ee0192e5d0501a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
