{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "game_titles = {\n",
    "    \"shuffleKeys_game\": \"Shuffle Keys Game\",\n",
    "    \"contingency_game\": \"Contingency Game\",\n",
    "    \"contingency_game_0\": \"Contingency Game (Single Seed)\",\n",
    "    \"contingency_game_r0\": \"Contingency Game (Agent Placement is Constant Among Each Level)\",\n",
    "    \"contingency_game_diff_color\": \"Contingency Game (Real Agent is Blue)\",\n",
    "    \"contingency_game_shuffled\": \"Shuffled Keys Game (Shuffled Once in Every 200 Levels)\",\n",
    "    \"logic_game\": \"Logic Game\",\n",
    "    \"logic_extended_game\": \"Ext Logic\",\n",
    "    \"change_agent_game\": \"Agent Change Game\"\n",
    "}\n",
    "\n",
    "label_dict = {'human': 'Human', 'self_class': 'Self Class', 'dqn_training': 'DQN',\n",
    "              'random': 'Random', 'a2c_training': \"A2C\", 'trpo_training': 'TRPO', 'ppo2_training': 'PPO2',\n",
    "              'acer_training': 'ACER'}\n",
    "\n",
    "\n",
    "def ts_plotter(self, ax, data1, data2):\n",
    "    '''\n",
    "    Helper for plotting panels in time series plot.\n",
    "    '''\n",
    "\n",
    "    out = ax.plot(data1, data2, linewidth=2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(game_types, agent_types, batch_size=10, single_seed=False):\n",
    "    ''' Plot performance for games and agents'''\n",
    "    param_dict = {}\n",
    "\n",
    "    ## ----- Read in data\n",
    "    ext_data = []\n",
    "    for i, game_type in enumerate(game_types):\n",
    "        param_dict[game_type] = {}\n",
    "        for agent_type in agent_types:\n",
    "            files = glob.glob(\"../data/\" + game_type + \"/\" + agent_type + \"/*/*.json\")\n",
    "            if len(files) == 0:\n",
    "                files = glob.glob(\"../data/\" + game_type + \"/\" + agent_type + \"/*.json\")\n",
    "\n",
    "            seed = 0\n",
    "            curr_file_count = 0\n",
    "            file_amt = len(files)\n",
    "            param_dict[game_type][agent_type] = {}\n",
    "            seed_current = []\n",
    "            all_seeds = []\n",
    "            seed_total = 10 if not single_seed else 1\n",
    "            for i, file in enumerate(sorted(files, key=os.path.getmtime)):\n",
    "                with open(file, 'r') as fp:\n",
    "                    #if agent_type == 'human' and game_type == 'logic':  # TODO: change after we get data\n",
    "                    #    f = open(file, 'rb')\n",
    "                    #    param_dict[game_type][agent_type] = pickle.load(f)\n",
    "                    #    continue\n",
    "\n",
    "                    data = json.load(fp)\n",
    "                    param_dict[game_type][agent_type] = data['data']['steps']\n",
    "                    curr_file_count += 1\n",
    "\n",
    "                    seed_current.append(data['data']['steps'])\n",
    "\n",
    "                    if file_amt == 1:\n",
    "                        param_dict[game_type][agent_type] = [data['data']['steps']]\n",
    "                        break\n",
    "                    else:\n",
    "                        if agent_type == 'human' and curr_file_count == file_amt:\n",
    "                            param_dict[game_type][agent_type] = seed_current\n",
    "                            break\n",
    "\n",
    "                    if agent_type != 'human' and curr_file_count == 20:\n",
    "                        all_seeds.append(seed_current)\n",
    "                        seed_current = []\n",
    "                        curr_file_count = 0\n",
    "                        seed += 1\n",
    "\n",
    "                    if seed == seed_total:\n",
    "                        param_dict[game_type][agent_type] = all_seeds\n",
    "                        all_seeds = []\n",
    "\n",
    "                        if single_seed:\n",
    "                            break\n",
    "\n",
    "    ## ---- Get descriptive statistics\n",
    "    stats_dict = {}\n",
    "    for game_type in game_types:\n",
    "        stats_dict[game_type] = {}\n",
    "        for agent_type in agent_types:\n",
    "            raw_data = pd.DataFrame(param_dict[game_type][agent_type])\n",
    "\n",
    "            seed_average = []\n",
    "            seed_sem = []\n",
    "            for column in raw_data:\n",
    "                seed_average.append(np.mean(list(raw_data[column]), axis=0))\n",
    "                seed_sem.append((pd.DataFrame(list(raw_data[column]))).sem(axis=0))\n",
    "\n",
    "            # TODO\n",
    "            # curr_data = pd.concat([pd.DataFrame(seed_average).T, pd.DataFrame(ext_avg).T], ignore_index=True)\n",
    "            curr_avg_data = pd.DataFrame(seed_average).T\n",
    "            curr_sem_data = pd.DataFrame(seed_sem).T\n",
    "            stats_dict[game_type][agent_type] = raw_data\n",
    "            if agent_type != 'human':\n",
    "                stats_dict[game_type][agent_type + \"_m\"] = np.array(\n",
    "                    [curr_avg_data[column].groupby(curr_avg_data.index // batch_size).mean() for column in curr_avg_data]).reshape(\n",
    "                    int(curr_avg_data.shape[1] * 100 * 1 / batch_size))\n",
    "                stats_dict[game_type][agent_type + \"_se\"] = np.array(\n",
    "                    [curr_sem_data[column].groupby(curr_sem_data.index // batch_size).sem() for column in curr_sem_data]).reshape(\n",
    "                    int(curr_sem_data.shape[1] * 100 * 1 / batch_size))\n",
    "            else:\n",
    "                temp = np.asarray(curr_avg_data).T\n",
    "                avg_ma = [temp[i:i+batch_size].mean() for i in range(0, curr_avg_data.shape[1] - batch_size + 1, batch_size)]\n",
    "\n",
    "                temp = np.asarray(curr_sem_data).T\n",
    "                avg_se = [temp[i:i+batch_size].mean() for i in range(0, curr_sem_data.shape[1] - batch_size + 1, batch_size)]\n",
    "\n",
    "                stats_dict[game_type][agent_type + \"_m\"] = np.array(avg_ma).reshape(int(curr_avg_data.shape[1] / batch_size))\n",
    "                stats_dict[game_type][agent_type + \"_se\"] = np.array(avg_se).reshape(int(curr_sem_data.shape[1] / batch_size))\n",
    "\n",
    "    ## ---- Plot data\n",
    "    return stats_dict, game_types, agent_types, batch_size\n",
    "\n",
    "\n",
    "def plotter(stats, game_types, agent_types, batch_size, combined=False):\n",
    "    for i, game_type in enumerate(game_types):\n",
    "        st = stats[game_type]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        axes = plt.gca()\n",
    "        if game_type == 'contingency_game_shuffled':\n",
    "            axes.set_ylim([0, 6000])\n",
    "        elif game_type in ['contingency_game', 'contingency_game_diff_color', 'contingency_game_0']:\n",
    "            axes.set_ylim([0, 1000])\n",
    "        ax.xaxis.label.set_size(25)\n",
    "        ax.yaxis.label.set_size(25)\n",
    "        ax.set_xlabel(xlabel=\"Levels Played\", labelpad=21)\n",
    "        if combined:\n",
    "            y_str = \"No. of Steps to Complete Level ({} Level MA) \\nGame modified after 2000 Level Boundary\".format(\n",
    "                batch_size)\n",
    "        else:\n",
    "            y_str = \"No. of Steps to Complete Level ({} Level MA)\".format(\n",
    "                batch_size)\n",
    "\n",
    "        ax.set_ylabel(ylabel=y_str, labelpad=21)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=17)\n",
    "        ax.set_title(game_titles[game_type], fontweight='bold', fontsize=25)\n",
    "\n",
    "        colors = [\"#0373fc\", \"#d002f5\", \"#000000\", \"#fa0047\", \"#ff8903\", \"#03fc9d\", \"#b7c4c1\"]\n",
    "        for i, agent_type in enumerate(agent_types):\n",
    "\n",
    "            if agent_type != 'human':\n",
    "                xs = [int(i * batch_size) for i in range(0, len(st[agent_type + \"_m\"]))]\n",
    "                r_l = ax.plot(xs, st[agent_type + \"_m\"], color=colors[i], linewidth=1, label=label_dict[agent_type])\n",
    "                x = [int(i * batch_size) for i in range(0, len(st[agent_type + \"_m\"]))]\n",
    "                ax.fill_between(x, st[agent_type + \"_m\"] - st[agent_type + \"_se\"],\n",
    "                                st[agent_type + \"_m\"] + st[agent_type + \"_se\"], alpha=0.08, color=colors[i])\n",
    "            else:\n",
    "                xs = [int(i * batch_size) for i in range(0, len(st[\"human_m\"]))]\n",
    "                hum_l = ax.plot(xs, st['human_m'], color=colors[i], linewidth=2,\n",
    "                                label=label_dict['human'])\n",
    "                x = [int(i * batch_size) for i in range(0, len(st[\"human_m\"]))]\n",
    "                ax.fill_between(x, st['human_m'] - st['human_se'],\n",
    "                                st['human_m'] + st['human_se'],\n",
    "                                alpha=0.08, color=colors[i])\n",
    "\n",
    "        # first_legend = plt.legend(handles=[r_l[0], dqn_l[0], sc_l[0], hum_l[0]], loc='upper right', prop={'size': 22})\n",
    "        if combined:\n",
    "            plt.axvline(x=2000, color=\"#ffff03\", alpha=0.2, linewidth=15)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize='xx-large')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        fig.savefig('effiency_curves_' + game_type + '{}.pdf'.format('_' + str(batch_size)), format='pdf')\n",
    "\n",
    "\n",
    "# Append stats of two data (normal + extended)\n",
    "def append_stats(dict_normal, dict_ext, game_types, game_types_ext, agent_types):\n",
    "    appended_data = {}\n",
    "    for i, game in enumerate(game_types):\n",
    "        appended_data[game] = {}\n",
    "        for agent in agent_types:\n",
    "            for key, value in dict_normal[game].items():\n",
    "                data_normal = dict_normal[game][key]\n",
    "                data_ext = dict_ext[game_types_ext[i]][key]\n",
    "                appended_data[game][key] = np.concatenate((data_normal, data_ext))\n",
    "\n",
    "    return appended_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "game_types = [\"logic_game\"]  #, \"change_agent_game\", \"contingency_game_shuffled\"] #\"logic_game\",\n",
    "agent_types = [\"human\", \"dqn_training\", \"a2c_training\", \"trpo_training\", \"acer_training\", \"ppo2_training\", \"self_class\", \"random\"]\n",
    "batch_size = 20\n",
    "\n",
    "for game in game_types:\n",
    "    stats_dict, game_types, agent_types, batch_size = get_performance([game], agent_types,\n",
    "                                                                              batch_size, single_seed=False)\n",
    "\n",
    "    plotter(stats_dict, game_types, agent_types, batch_size, False)\n",
    "\n",
    "\n",
    "# Get performance stats of extended game\n",
    "# game_types_ext = [\"logic_extended_game\"]\n",
    "# agent_types_ext = [\"dqn_training\", \"trpo_training\", \"a2c_training\", \"acer_training\"]\n",
    "# stats_dict_ext, game_types_ext, agent_types_ext, y_lims_ext, batch_size_ext = get_performance(game_types_ext,\n",
    "#                                                                                              agent_types_ext,\n",
    "#                                                                                              y_lims, batch_size)\n",
    "\n",
    "# appended_stats = append_stats(stats_dict, stats_dict_ext, game_types, game_types_ext, agent_types)\n",
    "# plotter(appended_stats, game_types, agent_types, y_lims, batch_size, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----- Plot the number of steps the player takes before any agent moves from its starting location\n",
    "\n",
    "# Plot non-moving action count of agent for each level\n",
    "def plot_nm_ac(game_types, agent_types, batch_size=20):\n",
    "    for i, game_type in enumerate(game_types):\n",
    "        nm_ac = get_all_nm_ac(agent_types, game_type, batch_size)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        ax.set_ylim([0, 10])\n",
    "        ax.xaxis.label.set_size(25)\n",
    "        ax.yaxis.label.set_size(25)\n",
    "        ax.set_xlabel(xlabel=\"Levels Played\", labelpad=21)\n",
    "        ax.set_ylabel(ylabel=\"Action Count Until Movement ({} Level MA)\".format(batch_size), labelpad=21)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=17)\n",
    "        game_label_dict = {'logic_game': \"Logic Game\"}\n",
    "        ax.set_title(game_label_dict[game_type], fontweight='bold', fontsize=25)\n",
    "\n",
    "        colors = [\"#0373fc\", \"#d002f5\", \"#000000\", \"#fa0047\", \"#ff8903\", \"#03fc9d\", \"#b7c4c1\"]\n",
    "        agent_label_dict = {'dqn_training': 'DQN', 'human': \"Human\", \"self_class\": \"Self Class\", \"random\": \"Random\",\n",
    "                            'a2c_training': \"A2C\", 'trpo_training': 'TRPO', 'ppo2_training': 'PPO2',\n",
    "                            \"acer_training\": \"ACER\"}\n",
    "        for j, agent in enumerate(agent_types):\n",
    "\n",
    "            if agent == 'human':\n",
    "                xs = [int(i * batch_size) for i in range(0, len(nm_ac[agent + \"_m\"]) + 1)]\n",
    "                ax.plot(xs, nm_ac[agent + \"_m\"], color=colors[j], linewidth=1,\n",
    "                        label=agent_label_dict[agent])\n",
    "                upper_curve = [nm_ac[agent + '_m'][i] + nm_ac[agent + '_se'][i] for i in\n",
    "                               range(len(nm_ac[agent + '_m']))]\n",
    "                lower_curve = [nm_ac[agent + '_m'][i] - nm_ac[agent + '_se'][i] for i in\n",
    "                               range(len(nm_ac[agent + '_m']))]\n",
    "                x = [int(i * batch_size) for i in range(0, len(nm_ac[agent + \"_m\"]) + 1)]\n",
    "                ax.fill_between(x, np.append(lower_curve, lower_curve[1]), np.append(upper_curve, upper_curve[1]),\n",
    "                                alpha=0.08, color=colors[j])\n",
    "            else:\n",
    "                xs = [int(i * batch_size) for i in range(0, len(nm_ac[agent + \"_m\"]))]\n",
    "                ax.plot(xs, nm_ac[agent + \"_m\"], color=colors[j], linewidth=1, label=agent_label_dict[agent])\n",
    "                upper_curve = [nm_ac[agent + '_m'][i] + nm_ac[agent + '_se'][i] for i in\n",
    "                               range(len(nm_ac[agent + '_m']))]\n",
    "                lower_curve = [nm_ac[agent + '_m'][i] - nm_ac[agent + '_se'][i] for i in\n",
    "                               range(len(nm_ac[agent + '_m']))]\n",
    "                x = [int(i * batch_size) for i in range(0, len(nm_ac[agent + \"_m\"]))]\n",
    "                ax.fill_between(x, lower_curve, upper_curve, alpha=0.08, color=colors[j])\n",
    "\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize='xx-large')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        fig.savefig('no_movement_action_count_{}.pdf'.format(game_type), format='pdf')\n",
    "\n",
    "\n",
    "# # Get non-moving action count of agent for each level and each game as a dictionary\n",
    "def get_all_nm_ac(agent_types, game_type, batch_size):\n",
    "    stats = {}\n",
    "    for agent in agent_types:\n",
    "        stats[agent + \"_m\"], stats[agent + \"_se\"] = get_nm_ac(agent, game_type, batch_size)\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "# Get non-moving action count of agent for each level\n",
    "def get_nm_ac(agent_type, game_type, batch_size):\n",
    "    files = glob.glob(\"../data/\" + game_type + \"/\" + agent_type + \"/*/*.json\")\n",
    "\n",
    "    if len(files) == 0:\n",
    "        files = glob.glob(\"../data/\" + game_type + \"/\" + agent_type + \"/*.json\")\n",
    "\n",
    "    all_seeds = []\n",
    "    curr_seed = []\n",
    "    seed = 0\n",
    "    curr_file_count = 0\n",
    "    file_amt = len(files)\n",
    "    for i, file in enumerate(sorted(files, key=os.path.getmtime)):\n",
    "        data = json.load(open(file))\n",
    "        self_locs = data.get(\"data\")[\"self_locs\"]\n",
    "\n",
    "        level_amt = 100\n",
    "        action_count = [1] * level_amt\n",
    "\n",
    "        # In each 100 levels:\n",
    "        for level in range(level_amt):\n",
    "            if len(self_locs[level]) == 0:\n",
    "                continue\n",
    "            action_amt = len(self_locs[level][0])\n",
    "            for i in range(action_amt):\n",
    "                if i == level_amt:\n",
    "                    break\n",
    "\n",
    "                x = self_locs[level][0][i]\n",
    "                y = self_locs[level][1][i]\n",
    "                x1 = self_locs[level][0][i + 1]\n",
    "                y1 = self_locs[level][1][i + 1]\n",
    "\n",
    "                if x == x1 and y == y1:  # Still in the same position\n",
    "                    action_count[level] = action_count[level] + 1\n",
    "                else:  # Position have changed\n",
    "                    break\n",
    "\n",
    "        curr_file_count += 1\n",
    "        curr_seed.append(action_count)\n",
    "\n",
    "        if agent_type == 'human' and (curr_file_count == file_amt or file_amt == 1):\n",
    "            all_seeds.append(curr_seed)\n",
    "            break\n",
    "\n",
    "        if agent_type != 'human' and curr_file_count == 20:\n",
    "            all_seeds.append(curr_seed)\n",
    "            curr_seed = []\n",
    "            curr_file_count = 0\n",
    "            seed += 1\n",
    "\n",
    "    seed_average = []\n",
    "    all_seeds = pd.DataFrame(all_seeds)\n",
    "    for column in all_seeds:\n",
    "        seed_average.append(np.mean(list(all_seeds[column]), axis=0))\n",
    "\n",
    "    all_seeds = pd.DataFrame(seed_average).T\n",
    "\n",
    "    seed_mean = np.array(\n",
    "        [all_seeds[column].groupby(all_seeds.index // batch_size).mean() for column in all_seeds]).reshape(\n",
    "        int(all_seeds.shape[1] * 100 * 1 / batch_size))\n",
    "    s_sem = np.array([all_seeds[column].groupby(all_seeds.index // batch_size).sem() for column in all_seeds]).reshape(\n",
    "        int(all_seeds.shape[1] * 100 * 1 / batch_size))\n",
    "\n",
    "    return seed_mean, s_sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "agent_types = [\"human\", \"dqn_training\", \"a2c_training\", \"trpo_training\", \"acer_training\", \"ppo2_training\", \"self_class\", \"random\"\n",
    "               ]\n",
    "game_types = [\"logic_game\"] #, \"contingency_game\", \"change_agent_game\", \"contingency_game_shuffled\"\n",
    "plot_nm_ac(game_types, agent_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}